{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcwGP8FaCkf5",
        "outputId": "c23a3c5b-2f9c-4f04-da00-107f337fbcbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install timm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhbzkZUGDT2E",
        "outputId": "3928b507-9387-496d-8cf5-141324c54575"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm\n",
            "  Downloading timm-0.9.8-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.16.0+cu118)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n",
            "Collecting huggingface-hub (from timm)\n",
            "  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors (from timm)\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (4.66.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (23.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.23.5)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n",
            "Installing collected packages: safetensors, huggingface-hub, timm\n",
            "Successfully installed huggingface-hub-0.18.0 safetensors-0.4.0 timm-0.9.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "import json\n",
        "import pathlib\n",
        "\n",
        "import timm\n",
        "import tqdm\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision\n",
        "import random\n"
      ],
      "metadata": {
        "id": "tffYQcBMDVqP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SUPERVISED LEARNING ON 20% OF THE DATASET"
      ],
      "metadata": {
        "id": "qO9K4YW4HDd3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_dataset_train = pathlib.Path(\"/content/gdrive/MyDrive/imagenette2-320/train\")\n",
        "path_dataset_val = pathlib.Path(\"/content/gdrive/MyDrive/imagenette2-320/val\")\n",
        "path_labels = pathlib.Path(\"/content/gdrive/MyDrive/imagenette2-320/imagenette_labels.json\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "n_workers = 2\n",
        "\n",
        "# Data related\n",
        "with path_labels.open(\"r\") as f:\n",
        "    label_mapping = json.load(f)\n",
        "\n",
        "transform_plain = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "        transforms.Resize((224, 224),antialias=True),\n",
        "    ]\n",
        ")\n",
        "dataset_train_plain = ImageFolder(path_dataset_train, transform=transform_plain)\n",
        "dataset_val_plain = ImageFolder(path_dataset_val, transform=transform_plain)\n",
        "\n",
        "if dataset_train_plain.classes != dataset_val_plain.classes:\n",
        "    raise ValueError(\"Inconsistent classes\")\n",
        "\n",
        "batch_size = 256\n",
        "data_loader_train_plain = DataLoader(dataset_train_plain,batch_size=batch_size, shuffle = True,\n",
        "    drop_last=False,num_workers=n_workers,)\n",
        "data_loader_val_plain = DataLoader(dataset_val_plain,batch_size=batch_size,\n",
        "    drop_last=True,num_workers=n_workers,shuffle = True)\n",
        "data_loader_val_plain_subset = DataLoader(dataset_val_plain,batch_size=batch_size,drop_last=False,\n",
        "    sampler=SubsetRandomSampler(list(range(0, len(dataset_val_plain), 50))),num_workers=n_workers,)\n"
      ],
      "metadata": {
        "id": "RT8XtgbxMNGA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class resnet(nn.Module):\n",
        "\n",
        "    def __init__(self,num_classes,pretrained = False):\n",
        "\n",
        "        super(resnet, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        if pretrained :\n",
        "          self.encoder = torchvision.models.resnet18(weights = \"DEFAULT\")\n",
        "        else:\n",
        "          self.encoder = torchvision.models.resnet18()\n",
        "        self.activation = nn.ReLU()\n",
        "        self.classifier = nn.Linear(1000,num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.encoder(x)\n",
        "        x =  self.activation(x)\n",
        "        x = self.classifier(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "F0vy-DojHLrc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting dataset\n",
        "n_train = len(dataset_train_plain)\n",
        "indices = list(range(n_train))\n",
        "random.shuffle(indices)\n",
        "\n",
        "split = int(np.floor(0.2 * n_train))\n",
        "train_indices, _ = indices[:split], indices[split:]\n",
        "\n",
        "n_test = len(dataset_val_plain)\n",
        "indices = list(range(n_test))\n",
        "random.shuffle(indices)\n",
        "\n",
        "split = int(np.floor(0.2 * n_test))\n",
        "test_indices, _ = indices[:split], indices[split:]\n",
        "\n",
        "train_supervised_sampler = SubsetRandomSampler(train_indices)\n",
        "test_supervised_sampler = SubsetRandomSampler(test_indices)\n",
        "\n",
        "data_loader_train_supervised = DataLoader(dataset_train_plain, batch_size=128,sampler=train_supervised_sampler, num_workers=n_workers)\n",
        "data_loader_test_supervised = DataLoader(dataset_val_plain, batch_size=128,sampler=test_supervised_sampler, num_workers=n_workers)\n",
        "\n"
      ],
      "metadata": {
        "id": "EdVCLzKFGFRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a model for supervised learning\n",
        "supervised_model = resnet(num_classes = 10,pretrained = False)\n",
        "# supervised_model = LeNet5(num_classes = 10)\n",
        "supervised_model = supervised_model.to(device)\n",
        "\n",
        "optimizer_supervised = torch.optim.Adam(supervised_model.parameters(), lr= 0.001)\n",
        "criterion = torch.nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "2jARZdN7RbAR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model_accuracy(test_loader, model, criterion):\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "    average_loss = 0\n",
        "    model.eval()\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, (img, label) in enumerate(test_loader):\n",
        "            img = img.to(device)\n",
        "            label = label.to(device)\n",
        "\n",
        "\n",
        "            output = model(img)\n",
        "            loss = criterion(output, label)\n",
        "            average_loss += loss.item()\n",
        "\n",
        "            # Calculate the accuracy\n",
        "            _, predicted_labels = output.max(1)\n",
        "            correct_predictions += (predicted_labels == label).sum().item()\n",
        "\n",
        "            total_samples += label.size(0)\n",
        "\n",
        "    test_accuracy = correct_predictions / total_samples\n",
        "    average_loss /= len(test_loader)\n",
        "    print(f'Test Accuracy: {test_accuracy:.4f}')\n",
        "    print(f'Average Test Loss : {average_loss:.4f}')\n",
        "    return test_accuracy,average_loss\n",
        "\n",
        "def train(train_loader,val_loader,model,optimizer,criterion,num_epochs):\n",
        "\n",
        "    training_loss = []\n",
        "    training_accuracy = []\n",
        "    testing_accuracy =[]\n",
        "    testing_loss = []\n",
        "    for i in range(num_epochs):\n",
        "        running_loss = 0\n",
        "        correct_predictions = 0\n",
        "        model.train()\n",
        "        for idx, (img,label) in enumerate(train_loader):\n",
        "\n",
        "            # label = torch.tensor(label)\n",
        "            bsz = label.shape[0]\n",
        "            optimizer.zero_grad()\n",
        "            img = img.to(device)\n",
        "            label = label.to(device)\n",
        "            prediction = model(img)\n",
        "\n",
        "            # Calculate the loss\n",
        "            loss = criterion(prediction, label)\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            # Calculate the accuracy\n",
        "            _, predicted_labels = prediction.max(1)\n",
        "            curr_predicted_labels = (predicted_labels == label).sum().item()\n",
        "            correct_predictions += curr_predicted_labels\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if idx%5 == 0:\n",
        "                print(f\"idx : {idx} , Current Loss(batch) : {loss.item()}, Correct Predictions(batch) : {curr_predicted_labels}/{bsz}\")\n",
        "\n",
        "        running_loss /= len(train_loader)\n",
        "        epoch_accuracy = correct_predictions / (1893)\n",
        "\n",
        "        print(f'Epoch: {i}, Loss (per batch) : {running_loss:.4f}, Accuracy: {epoch_accuracy:.4f}')\n",
        "\n",
        "        training_loss.append(running_loss)\n",
        "        training_accuracy.append(epoch_accuracy)\n",
        "\n",
        "        # test_accuracy(data_loader_val_subset,model)\n",
        "\n",
        "        t,l = test_model_accuracy(val_loader,model,criterion)\n",
        "        testing_accuracy.append(t)\n",
        "        testing_loss.append(l)\n",
        "\n",
        "    return training_loss, training_accuracy,testing_accuracy,testing_loss"
      ],
      "metadata": {
        "id": "spEjQJ7AGruA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TRAINING RESNET FROM SCRATCH**\n",
        "TRAINING LOSS : 0.03 \\\\\n",
        "TRAINING ACCURACY : 99% \\\\\n",
        "BEST TEST ACCURACY : 70%\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TlWXMO2xsCR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a1,b1,c1,d1 = train(data_loader_train_supervised,data_loader_test_supervised,supervised_model,optimizer_supervised,criterion,50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPhfE36qD4c8",
        "outputId": "4f6769fa-1fe9-4a80-804b-d8cb98dd5dc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "idx : 0 , Current Loss(batch) : 2.0837905406951904, Correct Predictions(batch) : 39/128\n",
            "idx : 5 , Current Loss(batch) : 1.90829598903656, Correct Predictions(batch) : 41/128\n",
            "idx : 10 , Current Loss(batch) : 1.9454395771026611, Correct Predictions(batch) : 40/128\n",
            "Epoch: 0, Loss (per batch) : 1.9312, Accuracy: 0.3170\n",
            "Test Accuracy: 0.1287\n",
            "Average Test Loss : 4.8453\n",
            "idx : 0 , Current Loss(batch) : 1.6776411533355713, Correct Predictions(batch) : 52/128\n",
            "idx : 5 , Current Loss(batch) : 1.8509056568145752, Correct Predictions(batch) : 42/128\n",
            "idx : 10 , Current Loss(batch) : 1.7008922100067139, Correct Predictions(batch) : 53/128\n",
            "Epoch: 1, Loss (per batch) : 1.7340, Accuracy: 0.3941\n",
            "Test Accuracy: 0.2599\n",
            "Average Test Loss : 2.2175\n",
            "idx : 0 , Current Loss(batch) : 1.5756869316101074, Correct Predictions(batch) : 61/128\n",
            "idx : 5 , Current Loss(batch) : 1.5255651473999023, Correct Predictions(batch) : 54/128\n",
            "idx : 10 , Current Loss(batch) : 1.4662233591079712, Correct Predictions(batch) : 66/128\n",
            "Epoch: 2, Loss (per batch) : 1.5457, Accuracy: 0.4696\n",
            "Test Accuracy: 0.3338\n",
            "Average Test Loss : 2.0663\n",
            "idx : 0 , Current Loss(batch) : 1.3946048021316528, Correct Predictions(batch) : 66/128\n",
            "idx : 5 , Current Loss(batch) : 1.5746268033981323, Correct Predictions(batch) : 63/128\n",
            "idx : 10 , Current Loss(batch) : 1.5664546489715576, Correct Predictions(batch) : 54/128\n",
            "Epoch: 3, Loss (per batch) : 1.4591, Accuracy: 0.4881\n",
            "Test Accuracy: 0.4331\n",
            "Average Test Loss : 1.7146\n",
            "idx : 0 , Current Loss(batch) : 1.5415809154510498, Correct Predictions(batch) : 54/128\n",
            "idx : 5 , Current Loss(batch) : 1.3490909337997437, Correct Predictions(batch) : 72/128\n",
            "idx : 10 , Current Loss(batch) : 1.2781636714935303, Correct Predictions(batch) : 66/128\n",
            "Epoch: 4, Loss (per batch) : 1.4004, Accuracy: 0.5077\n",
            "Test Accuracy: 0.3720\n",
            "Average Test Loss : 2.1312\n",
            "idx : 0 , Current Loss(batch) : 1.4941978454589844, Correct Predictions(batch) : 59/128\n",
            "idx : 5 , Current Loss(batch) : 1.3770607709884644, Correct Predictions(batch) : 67/128\n",
            "idx : 10 , Current Loss(batch) : 1.3519110679626465, Correct Predictions(batch) : 71/128\n",
            "Epoch: 5, Loss (per batch) : 1.3455, Accuracy: 0.5288\n",
            "Test Accuracy: 0.4051\n",
            "Average Test Loss : 1.7979\n",
            "idx : 0 , Current Loss(batch) : 1.1125627756118774, Correct Predictions(batch) : 81/128\n",
            "idx : 5 , Current Loss(batch) : 1.2799711227416992, Correct Predictions(batch) : 73/128\n",
            "idx : 10 , Current Loss(batch) : 1.2045371532440186, Correct Predictions(batch) : 70/128\n",
            "Epoch: 6, Loss (per batch) : 1.2100, Accuracy: 0.5800\n",
            "Test Accuracy: 0.3389\n",
            "Average Test Loss : 2.3436\n",
            "idx : 0 , Current Loss(batch) : 1.0706111192703247, Correct Predictions(batch) : 80/128\n",
            "idx : 5 , Current Loss(batch) : 1.1563347578048706, Correct Predictions(batch) : 78/128\n",
            "idx : 10 , Current Loss(batch) : 1.1298490762710571, Correct Predictions(batch) : 78/128\n",
            "Epoch: 7, Loss (per batch) : 1.1612, Accuracy: 0.6101\n",
            "Test Accuracy: 0.4522\n",
            "Average Test Loss : 1.7855\n",
            "idx : 0 , Current Loss(batch) : 1.2114070653915405, Correct Predictions(batch) : 75/128\n",
            "idx : 5 , Current Loss(batch) : 1.1576894521713257, Correct Predictions(batch) : 79/128\n",
            "idx : 10 , Current Loss(batch) : 0.9716202020645142, Correct Predictions(batch) : 87/128\n",
            "Epoch: 8, Loss (per batch) : 1.0786, Accuracy: 0.6403\n",
            "Test Accuracy: 0.4204\n",
            "Average Test Loss : 2.8886\n",
            "idx : 0 , Current Loss(batch) : 0.9384439587593079, Correct Predictions(batch) : 95/128\n",
            "idx : 5 , Current Loss(batch) : 1.0605851411819458, Correct Predictions(batch) : 75/128\n",
            "idx : 10 , Current Loss(batch) : 1.0348594188690186, Correct Predictions(batch) : 82/128\n",
            "Epoch: 9, Loss (per batch) : 0.9901, Accuracy: 0.6667\n",
            "Test Accuracy: 0.5363\n",
            "Average Test Loss : 1.5314\n",
            "idx : 0 , Current Loss(batch) : 0.784954845905304, Correct Predictions(batch) : 95/128\n",
            "idx : 5 , Current Loss(batch) : 1.0017457008361816, Correct Predictions(batch) : 80/128\n",
            "idx : 10 , Current Loss(batch) : 0.749374270439148, Correct Predictions(batch) : 94/128\n",
            "Epoch: 10, Loss (per batch) : 0.8775, Accuracy: 0.7058\n",
            "Test Accuracy: 0.5809\n",
            "Average Test Loss : 1.2722\n",
            "idx : 0 , Current Loss(batch) : 0.7570728063583374, Correct Predictions(batch) : 95/128\n",
            "idx : 5 , Current Loss(batch) : 0.8765528798103333, Correct Predictions(batch) : 92/128\n",
            "idx : 10 , Current Loss(batch) : 0.9150700569152832, Correct Predictions(batch) : 93/128\n",
            "Epoch: 11, Loss (per batch) : 0.8359, Accuracy: 0.7285\n",
            "Test Accuracy: 0.4395\n",
            "Average Test Loss : 2.2995\n",
            "idx : 0 , Current Loss(batch) : 0.673957347869873, Correct Predictions(batch) : 102/128\n",
            "idx : 5 , Current Loss(batch) : 0.7994346618652344, Correct Predictions(batch) : 90/128\n",
            "idx : 10 , Current Loss(batch) : 0.7876575589179993, Correct Predictions(batch) : 92/128\n",
            "Epoch: 12, Loss (per batch) : 0.7738, Accuracy: 0.7417\n",
            "Test Accuracy: 0.3822\n",
            "Average Test Loss : 3.6185\n",
            "idx : 0 , Current Loss(batch) : 1.027651309967041, Correct Predictions(batch) : 88/128\n",
            "idx : 5 , Current Loss(batch) : 0.785715639591217, Correct Predictions(batch) : 95/128\n",
            "idx : 10 , Current Loss(batch) : 0.8748266696929932, Correct Predictions(batch) : 92/128\n",
            "Epoch: 13, Loss (per batch) : 0.7628, Accuracy: 0.7522\n",
            "Test Accuracy: 0.4994\n",
            "Average Test Loss : 1.6104\n",
            "idx : 0 , Current Loss(batch) : 0.5835570693016052, Correct Predictions(batch) : 107/128\n",
            "idx : 5 , Current Loss(batch) : 0.5126155018806458, Correct Predictions(batch) : 107/128\n",
            "idx : 10 , Current Loss(batch) : 0.5988234281539917, Correct Predictions(batch) : 101/128\n",
            "Epoch: 14, Loss (per batch) : 0.6846, Accuracy: 0.7797\n",
            "Test Accuracy: 0.4828\n",
            "Average Test Loss : 1.7900\n",
            "idx : 0 , Current Loss(batch) : 0.4738915264606476, Correct Predictions(batch) : 105/128\n",
            "idx : 5 , Current Loss(batch) : 0.5813809037208557, Correct Predictions(batch) : 103/128\n",
            "idx : 10 , Current Loss(batch) : 0.6036157011985779, Correct Predictions(batch) : 102/128\n",
            "Epoch: 15, Loss (per batch) : 0.6043, Accuracy: 0.7929\n",
            "Test Accuracy: 0.4981\n",
            "Average Test Loss : 1.7734\n",
            "idx : 0 , Current Loss(batch) : 0.39174747467041016, Correct Predictions(batch) : 115/128\n",
            "idx : 5 , Current Loss(batch) : 0.4708567261695862, Correct Predictions(batch) : 107/128\n",
            "idx : 10 , Current Loss(batch) : 0.7573872208595276, Correct Predictions(batch) : 92/128\n",
            "Epoch: 16, Loss (per batch) : 0.5132, Accuracy: 0.8230\n",
            "Test Accuracy: 0.5172\n",
            "Average Test Loss : 2.3919\n",
            "idx : 0 , Current Loss(batch) : 0.5023577809333801, Correct Predictions(batch) : 102/128\n",
            "idx : 5 , Current Loss(batch) : 0.6104941964149475, Correct Predictions(batch) : 99/128\n",
            "idx : 10 , Current Loss(batch) : 0.6119533777236938, Correct Predictions(batch) : 97/128\n",
            "Epoch: 17, Loss (per batch) : 0.5256, Accuracy: 0.8220\n",
            "Test Accuracy: 0.4701\n",
            "Average Test Loss : 2.6259\n",
            "idx : 0 , Current Loss(batch) : 0.4028662443161011, Correct Predictions(batch) : 111/128\n",
            "idx : 5 , Current Loss(batch) : 0.43476924300193787, Correct Predictions(batch) : 111/128\n",
            "idx : 10 , Current Loss(batch) : 0.5841366648674011, Correct Predictions(batch) : 106/128\n",
            "Epoch: 18, Loss (per batch) : 0.4601, Accuracy: 0.8516\n",
            "Test Accuracy: 0.5529\n",
            "Average Test Loss : 1.6576\n",
            "idx : 0 , Current Loss(batch) : 0.3337397575378418, Correct Predictions(batch) : 116/128\n",
            "idx : 5 , Current Loss(batch) : 0.40432506799697876, Correct Predictions(batch) : 108/128\n",
            "idx : 10 , Current Loss(batch) : 0.5253493189811707, Correct Predictions(batch) : 108/128\n",
            "Epoch: 19, Loss (per batch) : 0.3468, Accuracy: 0.8901\n",
            "Test Accuracy: 0.5389\n",
            "Average Test Loss : 2.1115\n",
            "idx : 0 , Current Loss(batch) : 0.29058748483657837, Correct Predictions(batch) : 118/128\n",
            "idx : 5 , Current Loss(batch) : 0.23108811676502228, Correct Predictions(batch) : 116/128\n",
            "idx : 10 , Current Loss(batch) : 0.42219066619873047, Correct Predictions(batch) : 109/128\n",
            "Epoch: 20, Loss (per batch) : 0.3335, Accuracy: 0.8817\n",
            "Test Accuracy: 0.5108\n",
            "Average Test Loss : 2.7166\n",
            "idx : 0 , Current Loss(batch) : 0.4195936918258667, Correct Predictions(batch) : 109/128\n",
            "idx : 5 , Current Loss(batch) : 0.30499783158302307, Correct Predictions(batch) : 115/128\n",
            "idx : 10 , Current Loss(batch) : 0.37254202365875244, Correct Predictions(batch) : 117/128\n",
            "Epoch: 21, Loss (per batch) : 0.3799, Accuracy: 0.8690\n",
            "Test Accuracy: 0.5541\n",
            "Average Test Loss : 2.0699\n",
            "idx : 0 , Current Loss(batch) : 0.16922953724861145, Correct Predictions(batch) : 121/128\n",
            "idx : 5 , Current Loss(batch) : 0.5300301313400269, Correct Predictions(batch) : 108/128\n",
            "idx : 10 , Current Loss(batch) : 0.2984018623828888, Correct Predictions(batch) : 117/128\n",
            "Epoch: 22, Loss (per batch) : 0.3188, Accuracy: 0.8943\n",
            "Test Accuracy: 0.5618\n",
            "Average Test Loss : 1.9010\n",
            "idx : 0 , Current Loss(batch) : 0.1823810338973999, Correct Predictions(batch) : 118/128\n",
            "idx : 5 , Current Loss(batch) : 0.2178289145231247, Correct Predictions(batch) : 118/128\n",
            "idx : 10 , Current Loss(batch) : 0.3918841779232025, Correct Predictions(batch) : 112/128\n",
            "Epoch: 23, Loss (per batch) : 0.2774, Accuracy: 0.8986\n",
            "Test Accuracy: 0.5223\n",
            "Average Test Loss : 2.1121\n",
            "idx : 0 , Current Loss(batch) : 0.2765030562877655, Correct Predictions(batch) : 114/128\n",
            "idx : 5 , Current Loss(batch) : 0.25966230034828186, Correct Predictions(batch) : 113/128\n",
            "idx : 10 , Current Loss(batch) : 0.32613420486450195, Correct Predictions(batch) : 114/128\n",
            "Epoch: 24, Loss (per batch) : 0.2489, Accuracy: 0.9081\n",
            "Test Accuracy: 0.4790\n",
            "Average Test Loss : 3.8950\n",
            "idx : 0 , Current Loss(batch) : 0.38139456510543823, Correct Predictions(batch) : 112/128\n",
            "idx : 5 , Current Loss(batch) : 0.15455883741378784, Correct Predictions(batch) : 123/128\n",
            "idx : 10 , Current Loss(batch) : 0.2887797951698303, Correct Predictions(batch) : 119/128\n",
            "Epoch: 25, Loss (per batch) : 0.2010, Accuracy: 0.9366\n",
            "Test Accuracy: 0.6025\n",
            "Average Test Loss : 2.0755\n",
            "idx : 0 , Current Loss(batch) : 0.06712552905082703, Correct Predictions(batch) : 126/128\n",
            "idx : 5 , Current Loss(batch) : 0.09921620786190033, Correct Predictions(batch) : 124/128\n",
            "idx : 10 , Current Loss(batch) : 0.1404276341199875, Correct Predictions(batch) : 122/128\n",
            "Epoch: 26, Loss (per batch) : 0.1036, Accuracy: 0.9667\n",
            "Test Accuracy: 0.5962\n",
            "Average Test Loss : 1.9887\n",
            "idx : 0 , Current Loss(batch) : 0.05525039881467819, Correct Predictions(batch) : 126/128\n",
            "idx : 5 , Current Loss(batch) : 0.11276640743017197, Correct Predictions(batch) : 125/128\n",
            "idx : 10 , Current Loss(batch) : 0.07806343585252762, Correct Predictions(batch) : 122/128\n",
            "Epoch: 27, Loss (per batch) : 0.0939, Accuracy: 0.9672\n",
            "Test Accuracy: 0.6229\n",
            "Average Test Loss : 1.9343\n",
            "idx : 0 , Current Loss(batch) : 0.13266855478286743, Correct Predictions(batch) : 122/128\n",
            "idx : 5 , Current Loss(batch) : 0.15491311252117157, Correct Predictions(batch) : 122/128\n",
            "idx : 10 , Current Loss(batch) : 0.10150212794542313, Correct Predictions(batch) : 124/128\n",
            "Epoch: 28, Loss (per batch) : 0.1178, Accuracy: 0.9646\n",
            "Test Accuracy: 0.6064\n",
            "Average Test Loss : 2.1326\n",
            "idx : 0 , Current Loss(batch) : 0.07800024747848511, Correct Predictions(batch) : 124/128\n",
            "idx : 5 , Current Loss(batch) : 0.15328431129455566, Correct Predictions(batch) : 121/128\n",
            "idx : 10 , Current Loss(batch) : 0.13554002344608307, Correct Predictions(batch) : 125/128\n",
            "Epoch: 29, Loss (per batch) : 0.1343, Accuracy: 0.9562\n",
            "Test Accuracy: 0.6191\n",
            "Average Test Loss : 2.1259\n",
            "idx : 0 , Current Loss(batch) : 0.0848550796508789, Correct Predictions(batch) : 123/128\n",
            "idx : 5 , Current Loss(batch) : 0.08901648968458176, Correct Predictions(batch) : 124/128\n",
            "idx : 10 , Current Loss(batch) : 0.12508690357208252, Correct Predictions(batch) : 122/128\n",
            "Epoch: 30, Loss (per batch) : 0.1410, Accuracy: 0.9525\n",
            "Test Accuracy: 0.5376\n",
            "Average Test Loss : 2.9917\n",
            "idx : 0 , Current Loss(batch) : 0.11026553809642792, Correct Predictions(batch) : 125/128\n",
            "idx : 5 , Current Loss(batch) : 0.1306549459695816, Correct Predictions(batch) : 123/128\n",
            "idx : 10 , Current Loss(batch) : 0.06080113351345062, Correct Predictions(batch) : 124/128\n",
            "Epoch: 31, Loss (per batch) : 0.1063, Accuracy: 0.9651\n",
            "Test Accuracy: 0.5006\n",
            "Average Test Loss : 3.0696\n",
            "idx : 0 , Current Loss(batch) : 0.07310596853494644, Correct Predictions(batch) : 126/128\n",
            "idx : 5 , Current Loss(batch) : 0.11695245653390884, Correct Predictions(batch) : 120/128\n",
            "idx : 10 , Current Loss(batch) : 0.10179821401834488, Correct Predictions(batch) : 124/128\n",
            "Epoch: 32, Loss (per batch) : 0.1041, Accuracy: 0.9635\n",
            "Test Accuracy: 0.5745\n",
            "Average Test Loss : 2.4653\n",
            "idx : 0 , Current Loss(batch) : 0.08185421675443649, Correct Predictions(batch) : 124/128\n",
            "idx : 5 , Current Loss(batch) : 0.052988748997449875, Correct Predictions(batch) : 126/128\n",
            "idx : 10 , Current Loss(batch) : 0.10475461184978485, Correct Predictions(batch) : 127/128\n",
            "Epoch: 33, Loss (per batch) : 0.1165, Accuracy: 0.9604\n",
            "Test Accuracy: 0.5121\n",
            "Average Test Loss : 2.8155\n",
            "idx : 0 , Current Loss(batch) : 0.07560597360134125, Correct Predictions(batch) : 124/128\n",
            "idx : 5 , Current Loss(batch) : 0.06920715421438217, Correct Predictions(batch) : 125/128\n",
            "idx : 10 , Current Loss(batch) : 0.2311554104089737, Correct Predictions(batch) : 122/128\n",
            "Epoch: 34, Loss (per batch) : 0.1108, Accuracy: 0.9657\n",
            "Test Accuracy: 0.5287\n",
            "Average Test Loss : 2.4636\n",
            "idx : 0 , Current Loss(batch) : 0.08162045478820801, Correct Predictions(batch) : 125/128\n",
            "idx : 5 , Current Loss(batch) : 0.07859912514686584, Correct Predictions(batch) : 124/128\n",
            "idx : 10 , Current Loss(batch) : 0.09225790202617645, Correct Predictions(batch) : 124/128\n",
            "Epoch: 35, Loss (per batch) : 0.0796, Accuracy: 0.9709\n",
            "Test Accuracy: 0.6140\n",
            "Average Test Loss : 1.9340\n",
            "idx : 0 , Current Loss(batch) : 0.029139239341020584, Correct Predictions(batch) : 126/128\n",
            "idx : 5 , Current Loss(batch) : 0.03600451722741127, Correct Predictions(batch) : 127/128\n",
            "idx : 10 , Current Loss(batch) : 0.07151363044977188, Correct Predictions(batch) : 124/128\n",
            "Epoch: 36, Loss (per batch) : 0.0562, Accuracy: 0.9836\n",
            "Test Accuracy: 0.6153\n",
            "Average Test Loss : 2.4547\n",
            "idx : 0 , Current Loss(batch) : 0.044583458453416824, Correct Predictions(batch) : 126/128\n",
            "idx : 5 , Current Loss(batch) : 0.050842925906181335, Correct Predictions(batch) : 126/128\n",
            "idx : 10 , Current Loss(batch) : 0.04078243672847748, Correct Predictions(batch) : 125/128\n",
            "Epoch: 37, Loss (per batch) : 0.0614, Accuracy: 0.9789\n",
            "Test Accuracy: 0.6178\n",
            "Average Test Loss : 2.1877\n",
            "idx : 0 , Current Loss(batch) : 0.026730109006166458, Correct Predictions(batch) : 127/128\n",
            "idx : 5 , Current Loss(batch) : 0.03157537803053856, Correct Predictions(batch) : 127/128\n",
            "idx : 10 , Current Loss(batch) : 0.02555268257856369, Correct Predictions(batch) : 128/128\n",
            "Epoch: 38, Loss (per batch) : 0.0294, Accuracy: 0.9926\n",
            "Test Accuracy: 0.6166\n",
            "Average Test Loss : 2.1651\n",
            "idx : 0 , Current Loss(batch) : 0.01153599377721548, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.004220021888613701, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.014315036125481129, Correct Predictions(batch) : 128/128\n",
            "Epoch: 39, Loss (per batch) : 0.0239, Accuracy: 0.9926\n",
            "Test Accuracy: 0.6191\n",
            "Average Test Loss : 2.2093\n",
            "idx : 0 , Current Loss(batch) : 0.021048055961728096, Correct Predictions(batch) : 127/128\n",
            "idx : 5 , Current Loss(batch) : 0.018467675894498825, Correct Predictions(batch) : 127/128\n",
            "idx : 10 , Current Loss(batch) : 0.0074938577599823475, Correct Predictions(batch) : 128/128\n",
            "Epoch: 40, Loss (per batch) : 0.0111, Accuracy: 0.9984\n",
            "Test Accuracy: 0.6586\n",
            "Average Test Loss : 1.7727\n",
            "idx : 0 , Current Loss(batch) : 0.003107865108177066, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.003389375051483512, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.006895432714372873, Correct Predictions(batch) : 128/128\n",
            "Epoch: 41, Loss (per batch) : 0.0055, Accuracy: 0.9995\n",
            "Test Accuracy: 0.6739\n",
            "Average Test Loss : 1.9302\n",
            "idx : 0 , Current Loss(batch) : 0.0017713053384795785, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.0020362879149615765, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.004797326400876045, Correct Predictions(batch) : 128/128\n",
            "Epoch: 42, Loss (per batch) : 0.0032, Accuracy: 1.0000\n",
            "Test Accuracy: 0.6790\n",
            "Average Test Loss : 1.8428\n",
            "idx : 0 , Current Loss(batch) : 0.0014248898951336741, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.0006475038826465607, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.0012513594701886177, Correct Predictions(batch) : 128/128\n",
            "Epoch: 43, Loss (per batch) : 0.0016, Accuracy: 1.0000\n",
            "Test Accuracy: 0.6790\n",
            "Average Test Loss : 2.0056\n",
            "idx : 0 , Current Loss(batch) : 0.0003815982781816274, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.000699755153618753, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.001075949752703309, Correct Predictions(batch) : 128/128\n",
            "Epoch: 44, Loss (per batch) : 0.0009, Accuracy: 1.0000\n",
            "Test Accuracy: 0.6790\n",
            "Average Test Loss : 1.9444\n",
            "idx : 0 , Current Loss(batch) : 0.0003788139147218317, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.0010354411788284779, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.000490908685605973, Correct Predictions(batch) : 128/128\n",
            "Epoch: 45, Loss (per batch) : 0.0008, Accuracy: 1.0000\n",
            "Test Accuracy: 0.6854\n",
            "Average Test Loss : 1.8007\n",
            "idx : 0 , Current Loss(batch) : 0.00013653305359184742, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.0005688297096639872, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.0002487463934812695, Correct Predictions(batch) : 128/128\n",
            "Epoch: 46, Loss (per batch) : 0.0003, Accuracy: 1.0000\n",
            "Test Accuracy: 0.6854\n",
            "Average Test Loss : 1.9679\n",
            "idx : 0 , Current Loss(batch) : 0.00019971415167674422, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.001202161656692624, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.0004968802677467465, Correct Predictions(batch) : 128/128\n",
            "Epoch: 47, Loss (per batch) : 0.0005, Accuracy: 1.0000\n",
            "Test Accuracy: 0.6866\n",
            "Average Test Loss : 1.8881\n",
            "idx : 0 , Current Loss(batch) : 0.000226581483730115, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.00022433281992562115, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.004435840994119644, Correct Predictions(batch) : 128/128\n",
            "Epoch: 48, Loss (per batch) : 0.0006, Accuracy: 1.0000\n",
            "Test Accuracy: 0.7006\n",
            "Average Test Loss : 1.8205\n",
            "idx : 0 , Current Loss(batch) : 0.00021496866247616708, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.00019667070591822267, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.00016513392620254308, Correct Predictions(batch) : 128/128\n",
            "Epoch: 49, Loss (per batch) : 0.0003, Accuracy: 1.0000\n",
            "Test Accuracy: 0.6892\n",
            "Average Test Loss : 1.8916\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **FINE-TUNING USING IMAGENET PRETRAINED WEIGHTS**\n",
        "TRAINING LOSS : 0.03 \\\\\n",
        "TRAINING ACCURACY : 99% \\\\\n",
        "BEST TEST ACCURACY : 85.5%"
      ],
      "metadata": {
        "id": "aMn9wiHat7FH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a,b,c,d = train(data_loader_train_supervised,data_loader_test_supervised,supervised_model,optimizer_supervised,criterion,50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzGHbDjKa12Q",
        "outputId": "45f1c74b-1cc7-45a7-9a8e-c4e6484d6cf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "idx : 0 , Current Loss(batch) : 2.985105037689209, Correct Predictions(batch) : 5/128\n",
            "idx : 5 , Current Loss(batch) : 0.2605835497379303, Correct Predictions(batch) : 118/128\n",
            "idx : 10 , Current Loss(batch) : 0.4118060767650604, Correct Predictions(batch) : 110/128\n",
            "Epoch: 0, Loss (per batch) : 0.5977, Accuracy: 0.8267\n",
            "Test Accuracy: 0.5924\n",
            "Average Test Loss : 3.3110\n",
            "idx : 0 , Current Loss(batch) : 0.21699590981006622, Correct Predictions(batch) : 119/128\n",
            "idx : 5 , Current Loss(batch) : 0.18178032338619232, Correct Predictions(batch) : 121/128\n",
            "idx : 10 , Current Loss(batch) : 0.30990925431251526, Correct Predictions(batch) : 118/128\n",
            "Epoch: 1, Loss (per batch) : 0.2742, Accuracy: 0.9149\n",
            "Test Accuracy: 0.6471\n",
            "Average Test Loss : 2.4216\n",
            "idx : 0 , Current Loss(batch) : 0.18378369510173798, Correct Predictions(batch) : 123/128\n",
            "idx : 5 , Current Loss(batch) : 0.20953992009162903, Correct Predictions(batch) : 121/128\n",
            "idx : 10 , Current Loss(batch) : 0.1788659244775772, Correct Predictions(batch) : 119/128\n",
            "Epoch: 2, Loss (per batch) : 0.2096, Accuracy: 0.9387\n",
            "Test Accuracy: 0.6866\n",
            "Average Test Loss : 1.4839\n",
            "idx : 0 , Current Loss(batch) : 0.08101799339056015, Correct Predictions(batch) : 124/128\n",
            "idx : 5 , Current Loss(batch) : 0.13636991381645203, Correct Predictions(batch) : 125/128\n",
            "idx : 10 , Current Loss(batch) : 0.18677081167697906, Correct Predictions(batch) : 123/128\n",
            "Epoch: 3, Loss (per batch) : 0.1264, Accuracy: 0.9635\n",
            "Test Accuracy: 0.7656\n",
            "Average Test Loss : 0.9239\n",
            "idx : 0 , Current Loss(batch) : 0.0825258120894432, Correct Predictions(batch) : 125/128\n",
            "idx : 5 , Current Loss(batch) : 0.06253723800182343, Correct Predictions(batch) : 126/128\n",
            "idx : 10 , Current Loss(batch) : 0.04285240173339844, Correct Predictions(batch) : 127/128\n",
            "Epoch: 4, Loss (per batch) : 0.0751, Accuracy: 0.9799\n",
            "Test Accuracy: 0.7885\n",
            "Average Test Loss : 0.9095\n",
            "idx : 0 , Current Loss(batch) : 0.012925629504024982, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.037871211767196655, Correct Predictions(batch) : 127/128\n",
            "idx : 10 , Current Loss(batch) : 0.2131393849849701, Correct Predictions(batch) : 122/128\n",
            "Epoch: 5, Loss (per batch) : 0.0797, Accuracy: 0.9752\n",
            "Test Accuracy: 0.7771\n",
            "Average Test Loss : 0.8390\n",
            "idx : 0 , Current Loss(batch) : 0.05577843636274338, Correct Predictions(batch) : 125/128\n",
            "idx : 5 , Current Loss(batch) : 0.09799466282129288, Correct Predictions(batch) : 127/128\n",
            "idx : 10 , Current Loss(batch) : 0.08838145434856415, Correct Predictions(batch) : 124/128\n",
            "Epoch: 6, Loss (per batch) : 0.0824, Accuracy: 0.9757\n",
            "Test Accuracy: 0.7745\n",
            "Average Test Loss : 0.9214\n",
            "idx : 0 , Current Loss(batch) : 0.08009698987007141, Correct Predictions(batch) : 124/128\n",
            "idx : 5 , Current Loss(batch) : 0.03707433119416237, Correct Predictions(batch) : 127/128\n",
            "idx : 10 , Current Loss(batch) : 0.05498823896050453, Correct Predictions(batch) : 126/128\n",
            "Epoch: 7, Loss (per batch) : 0.0811, Accuracy: 0.9731\n",
            "Test Accuracy: 0.6688\n",
            "Average Test Loss : 1.9220\n",
            "idx : 0 , Current Loss(batch) : 0.04702313616871834, Correct Predictions(batch) : 127/128\n",
            "idx : 5 , Current Loss(batch) : 0.24123206734657288, Correct Predictions(batch) : 120/128\n",
            "idx : 10 , Current Loss(batch) : 0.08002472668886185, Correct Predictions(batch) : 125/128\n",
            "Epoch: 8, Loss (per batch) : 0.0799, Accuracy: 0.9794\n",
            "Test Accuracy: 0.7656\n",
            "Average Test Loss : 0.8932\n",
            "idx : 0 , Current Loss(batch) : 0.06978286802768707, Correct Predictions(batch) : 124/128\n",
            "idx : 5 , Current Loss(batch) : 0.10572536289691925, Correct Predictions(batch) : 123/128\n",
            "idx : 10 , Current Loss(batch) : 0.02239632047712803, Correct Predictions(batch) : 127/128\n",
            "Epoch: 9, Loss (per batch) : 0.0765, Accuracy: 0.9757\n",
            "Test Accuracy: 0.7643\n",
            "Average Test Loss : 0.9319\n",
            "idx : 0 , Current Loss(batch) : 0.022397708147764206, Correct Predictions(batch) : 127/128\n",
            "idx : 5 , Current Loss(batch) : 0.05426252633333206, Correct Predictions(batch) : 126/128\n",
            "idx : 10 , Current Loss(batch) : 0.10708063840866089, Correct Predictions(batch) : 125/128\n",
            "Epoch: 10, Loss (per batch) : 0.0826, Accuracy: 0.9715\n",
            "Test Accuracy: 0.6102\n",
            "Average Test Loss : 3.1376\n",
            "idx : 0 , Current Loss(batch) : 0.20742911100387573, Correct Predictions(batch) : 123/128\n",
            "idx : 5 , Current Loss(batch) : 0.09951608628034592, Correct Predictions(batch) : 124/128\n",
            "idx : 10 , Current Loss(batch) : 0.19535037875175476, Correct Predictions(batch) : 123/128\n",
            "Epoch: 11, Loss (per batch) : 0.1459, Accuracy: 0.9625\n",
            "Test Accuracy: 0.6484\n",
            "Average Test Loss : 2.2285\n",
            "idx : 0 , Current Loss(batch) : 0.16290608048439026, Correct Predictions(batch) : 124/128\n",
            "idx : 5 , Current Loss(batch) : 0.1732913851737976, Correct Predictions(batch) : 124/128\n",
            "idx : 10 , Current Loss(batch) : 0.1700165718793869, Correct Predictions(batch) : 122/128\n",
            "Epoch: 12, Loss (per batch) : 0.1784, Accuracy: 0.9509\n",
            "Test Accuracy: 0.6943\n",
            "Average Test Loss : 1.2727\n",
            "idx : 0 , Current Loss(batch) : 0.08629515767097473, Correct Predictions(batch) : 125/128\n",
            "idx : 5 , Current Loss(batch) : 0.12514819204807281, Correct Predictions(batch) : 122/128\n",
            "idx : 10 , Current Loss(batch) : 0.11470811069011688, Correct Predictions(batch) : 121/128\n",
            "Epoch: 13, Loss (per batch) : 0.1071, Accuracy: 0.9709\n",
            "Test Accuracy: 0.7529\n",
            "Average Test Loss : 1.0496\n",
            "idx : 0 , Current Loss(batch) : 0.06571432948112488, Correct Predictions(batch) : 126/128\n",
            "idx : 5 , Current Loss(batch) : 0.09625326097011566, Correct Predictions(batch) : 125/128\n",
            "idx : 10 , Current Loss(batch) : 0.16291603446006775, Correct Predictions(batch) : 124/128\n",
            "Epoch: 14, Loss (per batch) : 0.1060, Accuracy: 0.9699\n",
            "Test Accuracy: 0.7911\n",
            "Average Test Loss : 0.9052\n",
            "idx : 0 , Current Loss(batch) : 0.07725511491298676, Correct Predictions(batch) : 125/128\n",
            "idx : 5 , Current Loss(batch) : 0.13844995200634003, Correct Predictions(batch) : 125/128\n",
            "idx : 10 , Current Loss(batch) : 0.1724095344543457, Correct Predictions(batch) : 121/128\n",
            "Epoch: 15, Loss (per batch) : 0.1021, Accuracy: 0.9683\n",
            "Test Accuracy: 0.7363\n",
            "Average Test Loss : 1.1507\n",
            "idx : 0 , Current Loss(batch) : 0.12190751731395721, Correct Predictions(batch) : 125/128\n",
            "idx : 5 , Current Loss(batch) : 0.04250034689903259, Correct Predictions(batch) : 126/128\n",
            "idx : 10 , Current Loss(batch) : 0.021021351218223572, Correct Predictions(batch) : 128/128\n",
            "Epoch: 16, Loss (per batch) : 0.0821, Accuracy: 0.9741\n",
            "Test Accuracy: 0.7363\n",
            "Average Test Loss : 1.3696\n",
            "idx : 0 , Current Loss(batch) : 0.011856825090944767, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.03373397886753082, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.12868206202983856, Correct Predictions(batch) : 123/128\n",
            "Epoch: 17, Loss (per batch) : 0.0697, Accuracy: 0.9831\n",
            "Test Accuracy: 0.7796\n",
            "Average Test Loss : 0.9339\n",
            "idx : 0 , Current Loss(batch) : 0.011526652611792088, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.03271173685789108, Correct Predictions(batch) : 127/128\n",
            "idx : 10 , Current Loss(batch) : 0.020194940268993378, Correct Predictions(batch) : 127/128\n",
            "Epoch: 18, Loss (per batch) : 0.0606, Accuracy: 0.9815\n",
            "Test Accuracy: 0.7274\n",
            "Average Test Loss : 1.2253\n",
            "idx : 0 , Current Loss(batch) : 0.05495300516486168, Correct Predictions(batch) : 126/128\n",
            "idx : 5 , Current Loss(batch) : 0.18557171523571014, Correct Predictions(batch) : 121/128\n",
            "idx : 10 , Current Loss(batch) : 0.029104601591825485, Correct Predictions(batch) : 127/128\n",
            "Epoch: 19, Loss (per batch) : 0.0739, Accuracy: 0.9773\n",
            "Test Accuracy: 0.7516\n",
            "Average Test Loss : 1.2398\n",
            "idx : 0 , Current Loss(batch) : 0.07796099781990051, Correct Predictions(batch) : 123/128\n",
            "idx : 5 , Current Loss(batch) : 0.036575797945261, Correct Predictions(batch) : 127/128\n",
            "idx : 10 , Current Loss(batch) : 0.022358184680342674, Correct Predictions(batch) : 126/128\n",
            "Epoch: 20, Loss (per batch) : 0.0792, Accuracy: 0.9773\n",
            "Test Accuracy: 0.7618\n",
            "Average Test Loss : 0.9362\n",
            "idx : 0 , Current Loss(batch) : 0.028642555698752403, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.025821316987276077, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.057127129286527634, Correct Predictions(batch) : 126/128\n",
            "Epoch: 21, Loss (per batch) : 0.0487, Accuracy: 0.9831\n",
            "Test Accuracy: 0.8064\n",
            "Average Test Loss : 0.7410\n",
            "idx : 0 , Current Loss(batch) : 0.0038317216094583273, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.029551059007644653, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.014843457378447056, Correct Predictions(batch) : 128/128\n",
            "Epoch: 22, Loss (per batch) : 0.0630, Accuracy: 0.9857\n",
            "Test Accuracy: 0.7197\n",
            "Average Test Loss : 1.1213\n",
            "idx : 0 , Current Loss(batch) : 0.0236246045678854, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.03826896846294403, Correct Predictions(batch) : 126/128\n",
            "idx : 10 , Current Loss(batch) : 0.03279882296919823, Correct Predictions(batch) : 126/128\n",
            "Epoch: 23, Loss (per batch) : 0.0656, Accuracy: 0.9789\n",
            "Test Accuracy: 0.7376\n",
            "Average Test Loss : 1.0382\n",
            "idx : 0 , Current Loss(batch) : 0.034265633672475815, Correct Predictions(batch) : 126/128\n",
            "idx : 5 , Current Loss(batch) : 0.11098524183034897, Correct Predictions(batch) : 125/128\n",
            "idx : 10 , Current Loss(batch) : 0.03198951110243797, Correct Predictions(batch) : 128/128\n",
            "Epoch: 24, Loss (per batch) : 0.0998, Accuracy: 0.9725\n",
            "Test Accuracy: 0.7631\n",
            "Average Test Loss : 1.0276\n",
            "idx : 0 , Current Loss(batch) : 0.014994358643889427, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.09842900931835175, Correct Predictions(batch) : 125/128\n",
            "idx : 10 , Current Loss(batch) : 0.036565281450748444, Correct Predictions(batch) : 127/128\n",
            "Epoch: 25, Loss (per batch) : 0.0826, Accuracy: 0.9794\n",
            "Test Accuracy: 0.6433\n",
            "Average Test Loss : 1.8812\n",
            "idx : 0 , Current Loss(batch) : 0.08271729946136475, Correct Predictions(batch) : 125/128\n",
            "idx : 5 , Current Loss(batch) : 0.03416239842772484, Correct Predictions(batch) : 127/128\n",
            "idx : 10 , Current Loss(batch) : 0.013828977011144161, Correct Predictions(batch) : 128/128\n",
            "Epoch: 26, Loss (per batch) : 0.0835, Accuracy: 0.9757\n",
            "Test Accuracy: 0.6841\n",
            "Average Test Loss : 1.6205\n",
            "idx : 0 , Current Loss(batch) : 0.0762597918510437, Correct Predictions(batch) : 125/128\n",
            "idx : 5 , Current Loss(batch) : 0.1942724585533142, Correct Predictions(batch) : 123/128\n",
            "idx : 10 , Current Loss(batch) : 0.0994824767112732, Correct Predictions(batch) : 124/128\n",
            "Epoch: 27, Loss (per batch) : 0.1037, Accuracy: 0.9704\n",
            "Test Accuracy: 0.7631\n",
            "Average Test Loss : 0.8743\n",
            "idx : 0 , Current Loss(batch) : 0.11035159975290298, Correct Predictions(batch) : 125/128\n",
            "idx : 5 , Current Loss(batch) : 0.05369309335947037, Correct Predictions(batch) : 125/128\n",
            "idx : 10 , Current Loss(batch) : 0.24330611526966095, Correct Predictions(batch) : 120/128\n",
            "Epoch: 28, Loss (per batch) : 0.1191, Accuracy: 0.9672\n",
            "Test Accuracy: 0.8153\n",
            "Average Test Loss : 0.7945\n",
            "idx : 0 , Current Loss(batch) : 0.05780221149325371, Correct Predictions(batch) : 125/128\n",
            "idx : 5 , Current Loss(batch) : 0.0939626395702362, Correct Predictions(batch) : 125/128\n",
            "idx : 10 , Current Loss(batch) : 0.16149066388607025, Correct Predictions(batch) : 124/128\n",
            "Epoch: 29, Loss (per batch) : 0.0846, Accuracy: 0.9757\n",
            "Test Accuracy: 0.7796\n",
            "Average Test Loss : 0.8864\n",
            "idx : 0 , Current Loss(batch) : 0.018567612394690514, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.04092670604586601, Correct Predictions(batch) : 126/128\n",
            "idx : 10 , Current Loss(batch) : 0.040127288550138474, Correct Predictions(batch) : 126/128\n",
            "Epoch: 30, Loss (per batch) : 0.0454, Accuracy: 0.9873\n",
            "Test Accuracy: 0.7694\n",
            "Average Test Loss : 0.9790\n",
            "idx : 0 , Current Loss(batch) : 0.015764519572257996, Correct Predictions(batch) : 127/128\n",
            "idx : 5 , Current Loss(batch) : 0.04438463971018791, Correct Predictions(batch) : 126/128\n",
            "idx : 10 , Current Loss(batch) : 0.013613009825348854, Correct Predictions(batch) : 128/128\n",
            "Epoch: 31, Loss (per batch) : 0.0430, Accuracy: 0.9863\n",
            "Test Accuracy: 0.7287\n",
            "Average Test Loss : 1.0526\n",
            "idx : 0 , Current Loss(batch) : 0.0673936977982521, Correct Predictions(batch) : 124/128\n",
            "idx : 5 , Current Loss(batch) : 0.07161659747362137, Correct Predictions(batch) : 125/128\n",
            "idx : 10 , Current Loss(batch) : 0.0866413414478302, Correct Predictions(batch) : 124/128\n",
            "Epoch: 32, Loss (per batch) : 0.0553, Accuracy: 0.9836\n",
            "Test Accuracy: 0.7490\n",
            "Average Test Loss : 1.0366\n",
            "idx : 0 , Current Loss(batch) : 0.052595105022192, Correct Predictions(batch) : 126/128\n",
            "idx : 5 , Current Loss(batch) : 0.06044505909085274, Correct Predictions(batch) : 126/128\n",
            "idx : 10 , Current Loss(batch) : 0.10367462038993835, Correct Predictions(batch) : 124/128\n",
            "Epoch: 33, Loss (per batch) : 0.0903, Accuracy: 0.9736\n",
            "Test Accuracy: 0.7172\n",
            "Average Test Loss : 1.3956\n",
            "idx : 0 , Current Loss(batch) : 0.04538365453481674, Correct Predictions(batch) : 126/128\n",
            "idx : 5 , Current Loss(batch) : 0.03772464022040367, Correct Predictions(batch) : 126/128\n",
            "idx : 10 , Current Loss(batch) : 0.0636499673128128, Correct Predictions(batch) : 126/128\n",
            "Epoch: 34, Loss (per batch) : 0.0597, Accuracy: 0.9810\n",
            "Test Accuracy: 0.7783\n",
            "Average Test Loss : 0.9949\n",
            "idx : 0 , Current Loss(batch) : 0.0392441600561142, Correct Predictions(batch) : 127/128\n",
            "idx : 5 , Current Loss(batch) : 0.07005975395441055, Correct Predictions(batch) : 126/128\n",
            "idx : 10 , Current Loss(batch) : 0.02643006294965744, Correct Predictions(batch) : 127/128\n",
            "Epoch: 35, Loss (per batch) : 0.0460, Accuracy: 0.9868\n",
            "Test Accuracy: 0.7720\n",
            "Average Test Loss : 0.9804\n",
            "idx : 0 , Current Loss(batch) : 0.018490372225642204, Correct Predictions(batch) : 127/128\n",
            "idx : 5 , Current Loss(batch) : 0.005240897182375193, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.026854578405618668, Correct Predictions(batch) : 127/128\n",
            "Epoch: 36, Loss (per batch) : 0.0341, Accuracy: 0.9937\n",
            "Test Accuracy: 0.7898\n",
            "Average Test Loss : 0.8878\n",
            "idx : 0 , Current Loss(batch) : 0.0062679266557097435, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.007691664155572653, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.07218343019485474, Correct Predictions(batch) : 126/128\n",
            "Epoch: 37, Loss (per batch) : 0.0396, Accuracy: 0.9910\n",
            "Test Accuracy: 0.7350\n",
            "Average Test Loss : 0.8957\n",
            "idx : 0 , Current Loss(batch) : 0.004564508330076933, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.054525360465049744, Correct Predictions(batch) : 126/128\n",
            "idx : 10 , Current Loss(batch) : 0.009368353523314, Correct Predictions(batch) : 128/128\n",
            "Epoch: 38, Loss (per batch) : 0.0188, Accuracy: 0.9931\n",
            "Test Accuracy: 0.7669\n",
            "Average Test Loss : 0.9054\n",
            "idx : 0 , Current Loss(batch) : 0.00432333629578352, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.009825008921325207, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.012633425183594227, Correct Predictions(batch) : 127/128\n",
            "Epoch: 39, Loss (per batch) : 0.0105, Accuracy: 0.9979\n",
            "Test Accuracy: 0.8178\n",
            "Average Test Loss : 0.6881\n",
            "idx : 0 , Current Loss(batch) : 0.003434964222833514, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.0007691646460443735, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.0027284452226012945, Correct Predictions(batch) : 128/128\n",
            "Epoch: 40, Loss (per batch) : 0.0086, Accuracy: 0.9968\n",
            "Test Accuracy: 0.8382\n",
            "Average Test Loss : 0.5724\n",
            "idx : 0 , Current Loss(batch) : 0.0011721845949068666, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.009413926862180233, Correct Predictions(batch) : 127/128\n",
            "idx : 10 , Current Loss(batch) : 0.000745146709959954, Correct Predictions(batch) : 128/128\n",
            "Epoch: 41, Loss (per batch) : 0.0074, Accuracy: 0.9968\n",
            "Test Accuracy: 0.8229\n",
            "Average Test Loss : 0.6465\n",
            "idx : 0 , Current Loss(batch) : 0.002476446097716689, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.0015212582657113671, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.006514545995742083, Correct Predictions(batch) : 128/128\n",
            "Epoch: 42, Loss (per batch) : 0.0063, Accuracy: 0.9989\n",
            "Test Accuracy: 0.8344\n",
            "Average Test Loss : 0.5564\n",
            "idx : 0 , Current Loss(batch) : 0.001917530200444162, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.007685401011258364, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.0019277411047369242, Correct Predictions(batch) : 128/128\n",
            "Epoch: 43, Loss (per batch) : 0.0053, Accuracy: 0.9995\n",
            "Test Accuracy: 0.7873\n",
            "Average Test Loss : 0.7638\n",
            "idx : 0 , Current Loss(batch) : 0.0019643406849354506, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.002107533160597086, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.0006400615093298256, Correct Predictions(batch) : 128/128\n",
            "Epoch: 44, Loss (per batch) : 0.0036, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8382\n",
            "Average Test Loss : 0.5819\n",
            "idx : 0 , Current Loss(batch) : 0.002365180291235447, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.0005457819788716733, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.0029776340816169977, Correct Predictions(batch) : 128/128\n",
            "Epoch: 45, Loss (per batch) : 0.0031, Accuracy: 0.9995\n",
            "Test Accuracy: 0.8535\n",
            "Average Test Loss : 0.6955\n",
            "idx : 0 , Current Loss(batch) : 0.003294100984930992, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.0021104190964251757, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.006029978394508362, Correct Predictions(batch) : 128/128\n",
            "Epoch: 46, Loss (per batch) : 0.0029, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8433\n",
            "Average Test Loss : 0.5967\n",
            "idx : 0 , Current Loss(batch) : 0.0013030353002250195, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.00046445216867141426, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.0014854110777378082, Correct Predictions(batch) : 128/128\n",
            "Epoch: 47, Loss (per batch) : 0.0020, Accuracy: 0.9995\n",
            "Test Accuracy: 0.8369\n",
            "Average Test Loss : 0.6219\n",
            "idx : 0 , Current Loss(batch) : 0.0006612490396946669, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.027885757386684418, Correct Predictions(batch) : 127/128\n",
            "idx : 10 , Current Loss(batch) : 0.0024602364283055067, Correct Predictions(batch) : 128/128\n",
            "Epoch: 48, Loss (per batch) : 0.0050, Accuracy: 0.9995\n",
            "Test Accuracy: 0.8433\n",
            "Average Test Loss : 0.5523\n",
            "idx : 0 , Current Loss(batch) : 0.009907838888466358, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.0022639455273747444, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.00978080090135336, Correct Predictions(batch) : 128/128\n",
            "Epoch: 49, Loss (per batch) : 0.0066, Accuracy: 0.9979\n",
            "Test Accuracy: 0.8191\n",
            "Average Test Loss : 0.6433\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SUPERVISED LEARNING ON 100% TRAINING DATASET"
      ],
      "metadata": {
        "id": "D_qLiQqTcqWd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "data_loader_train_full = DataLoader(dataset_train_plain,batch_size=batch_size, shuffle = True,\n",
        "    drop_last=False,num_workers=n_workers,)\n",
        "data_loader_val_full = DataLoader(dataset_val_plain,batch_size=batch_size,\n",
        "    drop_last=True,num_workers=n_workers,shuffle = True)"
      ],
      "metadata": {
        "id": "SnbvJkIHibOl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a2,b2,c2,d2 = train(data_loader_train_full,data_loader_val_full,supervised_model,optimizer_supervised,criterion,50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbohJ3V-c60G",
        "outputId": "5bfa0f55-8daa-4a90-9c76-8048eae02018"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "idx : 0 , Current Loss(batch) : 1.6387784481048584, Correct Predictions(batch) : 56/128\n",
            "idx : 5 , Current Loss(batch) : 1.6421983242034912, Correct Predictions(batch) : 59/128\n",
            "idx : 10 , Current Loss(batch) : 1.520270824432373, Correct Predictions(batch) : 64/128\n",
            "idx : 15 , Current Loss(batch) : 1.5230779647827148, Correct Predictions(batch) : 62/128\n",
            "idx : 20 , Current Loss(batch) : 1.5206944942474365, Correct Predictions(batch) : 65/128\n",
            "idx : 25 , Current Loss(batch) : 1.6448556184768677, Correct Predictions(batch) : 58/128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DataAugmentation:\n",
        "    \"\"\"Create crops of an input image together with additional augmentation.\n",
        "\n",
        "    It generates 2 global crops and `n_local_crops` local crops.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    global_crops_scale : tuple\n",
        "        Range of sizes for the global crops.\n",
        "\n",
        "    local_crops_scale : tuple\n",
        "        Range of sizes for the local crops.\n",
        "\n",
        "    n_local_crops : int\n",
        "        Number of local crops to create.\n",
        "\n",
        "    size : int\n",
        "        The size of the final image.\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    global_1, global_2 : transforms.Compose\n",
        "        Two global transforms.\n",
        "\n",
        "    local : transforms.Compose\n",
        "        Local transform. Note that the augmentation is stochastic so one\n",
        "        instance is enough and will lead to different crops.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        global_crops_scale=(0.4, 1),\n",
        "        local_crops_scale=(0.05, 0.4),\n",
        "        n_local_crops=8,\n",
        "        size=224,\n",
        "    ):\n",
        "        self.n_local_crops = n_local_crops\n",
        "        RandomGaussianBlur = lambda p: transforms.RandomApply(  # noqa\n",
        "            [transforms.GaussianBlur(kernel_size=5, sigma=(0.1, 2))],\n",
        "            p=p,\n",
        "        )\n",
        "\n",
        "        flip_and_jitter = transforms.Compose(\n",
        "            [\n",
        "                transforms.RandomHorizontalFlip(p=0.5),\n",
        "                transforms.RandomApply(\n",
        "                    [\n",
        "                        transforms.ColorJitter(\n",
        "                            brightness=0.4,\n",
        "                            contrast=0.4,\n",
        "                            saturation=0.2,\n",
        "                            hue=0.1,\n",
        "                        ),\n",
        "                    ]\n",
        "                ),\n",
        "                transforms.RandomGrayscale(p=0.2),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        normalize = transforms.Compose(\n",
        "            [\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        self.global_1 = transforms.Compose(\n",
        "            [\n",
        "                transforms.RandomResizedCrop(\n",
        "                    size,\n",
        "                    scale=global_crops_scale,\n",
        "                    interpolation=Image.BICUBIC,\n",
        "                ),\n",
        "                flip_and_jitter,\n",
        "                RandomGaussianBlur(1.0),  # always apply\n",
        "                normalize,\n",
        "            ],\n",
        "        )\n",
        "\n",
        "        self.global_2 = transforms.Compose(\n",
        "            [\n",
        "                transforms.RandomResizedCrop(\n",
        "                    size,\n",
        "                    scale=global_crops_scale,\n",
        "                    interpolation=Image.BICUBIC,\n",
        "                ),\n",
        "                flip_and_jitter,\n",
        "                RandomGaussianBlur(0.1),\n",
        "                transforms.RandomSolarize(170, p=0.2),\n",
        "                normalize,\n",
        "            ],\n",
        "        )\n",
        "\n",
        "        self.local = transforms.Compose(\n",
        "            [\n",
        "                transforms.RandomResizedCrop(\n",
        "                    size,\n",
        "                    scale=local_crops_scale,\n",
        "                    interpolation=Image.BICUBIC,\n",
        "                ),\n",
        "                flip_and_jitter,\n",
        "                RandomGaussianBlur(0.5),\n",
        "                normalize,\n",
        "            ],\n",
        "        )\n",
        "\n",
        "    def __call__(self, img):\n",
        "        \"\"\"Apply transformation.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        img : PIL.Image\n",
        "            Input image.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        all_crops : list\n",
        "            List of `torch.Tensor` representing different views of\n",
        "            the input `img`.\n",
        "        \"\"\"\n",
        "        all_crops = []\n",
        "        all_crops.append(self.global_1(img))\n",
        "        all_crops.append(self.global_2(img))\n",
        "\n",
        "        all_crops.extend([self.local(img) for _ in range(self.n_local_crops)])\n",
        "\n",
        "        return all_crops\n",
        "\n",
        "class Head(nn.Module):\n",
        "    \"\"\"Network hooked up to the CLS token embedding.\n",
        "\n",
        "    Just a MLP with the last layer being normalized in a particular way.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    in_dim : int\n",
        "        The dimensionality of the token embedding.\n",
        "\n",
        "    out_dim : int\n",
        "        The dimensionality of the final layer (we compute the softmax over).\n",
        "\n",
        "    hidden_dim : int\n",
        "        Dimensionality of the hidden layers.\n",
        "\n",
        "    bottleneck_dim : int\n",
        "        Dimensionality of the second last layer.\n",
        "\n",
        "    n_layers : int\n",
        "        The number of layers.\n",
        "\n",
        "    norm_last_layer : bool\n",
        "        If True, then we freeze the norm of the weight of the last linear layer\n",
        "        to 1.\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    mlp : nn.Sequential\n",
        "        Vanilla multi-layer perceptron.\n",
        "\n",
        "    last_layer : nn.Linear\n",
        "        Reparametrized linear layer with weight normalization. That means\n",
        "        that that it will have `weight_g` and `weight_v` as learnable\n",
        "        parameters instead of a single `weight`.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_dim,\n",
        "        out_dim,\n",
        "        hidden_dim=2048,\n",
        "        bottleneck_dim=256,\n",
        "        n_layers=3,\n",
        "        norm_last_layer=False,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        if n_layers == 1:\n",
        "            self.mlp = nn.Linear(in_dim, bottleneck_dim)\n",
        "        else:\n",
        "            layers = [nn.Linear(in_dim, hidden_dim)]\n",
        "            layers.append(nn.GELU())\n",
        "            for _ in range(n_layers - 2):\n",
        "                layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
        "                layers.append(nn.GELU())\n",
        "            layers.append(nn.Linear(hidden_dim, bottleneck_dim))\n",
        "            self.mlp = nn.Sequential(*layers)\n",
        "\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "        self.last_layer = nn.utils.weight_norm(\n",
        "            nn.Linear(bottleneck_dim, out_dim, bias=False)\n",
        "        )\n",
        "        self.last_layer.weight_g.data.fill_(1)\n",
        "        if norm_last_layer:\n",
        "            self.last_layer.weight_g.requires_grad = False\n",
        "\n",
        "    def _init_weights(self, m):\n",
        "        \"\"\"Initialize learnable parameters.\"\"\"\n",
        "        if isinstance(m, nn.Linear):\n",
        "            nn.init.normal_(m.weight, std=0.02)\n",
        "            if m.bias is not None:\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Run forward pass.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : torch.Tensor\n",
        "            Of shape `(n_samples, in_dim)`.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        torch.Tensor\n",
        "            Of shape `(n_samples, out_dim)`.\n",
        "        \"\"\"\n",
        "        x = self.mlp(x)  # (n_samples, bottleneck_dim)\n",
        "        x = nn.functional.normalize(x, dim=-1, p=2)  # (n_samples, bottleneck_dim)\n",
        "        x = self.last_layer(x)  # (n_samples, out_dim)\n",
        "\n",
        "        return x\n",
        "\n",
        "class MultiCropWrapper(nn.Module):\n",
        "  \"\"\"Convenience class for forward pass of multiple crops.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  backbone : timm.models.vision_transformer.VisionTransformer\n",
        "      Instantiated Vision Transformer. Note that we will take the `head`\n",
        "      attribute and replace it with `nn.Identity`.\n",
        "\n",
        "  new_head : Head\n",
        "      New head that is going to be put on top of the `backbone`.\n",
        "  \"\"\"\n",
        "  def __init__(self, backbone, new_head):\n",
        "      super().__init__()\n",
        "      backbone.head = nn.Identity()  # deactivate original head\n",
        "      self.backbone = backbone\n",
        "      self.new_head = new_head\n",
        "\n",
        "  def forward(self, x):\n",
        "      \"\"\"Run the forward pass.\n",
        "\n",
        "      The different crops are concatenated along the batch dimension\n",
        "      and then a single forward pass is fun. The resulting tensor\n",
        "      is then chunked back to per crop tensors.\n",
        "\n",
        "      Parameters\n",
        "      ----------\n",
        "      x : list\n",
        "          List of `torch.Tensor` each of shape `(n_samples, 3, size, size)`.\n",
        "\n",
        "      Returns\n",
        "      -------\n",
        "      tuple\n",
        "          Tuple of `torch.Tensor` each of shape `(n_samples, out_dim)` where\n",
        "          `output_dim` is determined by `Head`.\n",
        "      \"\"\"\n",
        "      n_crops = len(x)\n",
        "      concatenated = torch.cat(x, dim=0)  # (n_samples * n_crops, 3, size, size)\n",
        "      cls_embedding = self.backbone(concatenated)  # (n_samples * n_crops, in_dim)\n",
        "      logits = self.new_head(cls_embedding)  # (n_samples * n_crops, out_dim)\n",
        "      chunks = logits.chunk(n_crops)  # n_crops * (n_samples, out_dim)\n",
        "\n",
        "      return chunks\n",
        "\n",
        "class Loss(nn.Module):\n",
        "    \"\"\"The loss function.\n",
        "\n",
        "    We subclass the `nn.Module` becuase we want to create a buffer for the\n",
        "    logits center of the teacher.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    out_dim : int\n",
        "        The dimensionality of the final layer (we computed the softmax over).\n",
        "\n",
        "    teacher_temp, student_temp : float\n",
        "        Softmax temperature of the teacher resp. student.\n",
        "\n",
        "    center_momentum : float\n",
        "        Hyperparameter for the exponential moving average that determines\n",
        "        the center logits. The higher the more the running average matters.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self, out_dim, teacher_temp=0.04, student_temp=0.1, center_momentum=0.9\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.student_temp = student_temp\n",
        "        self.teacher_temp = teacher_temp\n",
        "        self.center_momentum = center_momentum\n",
        "        self.register_buffer(\"center\", torch.zeros(1, out_dim))\n",
        "\n",
        "    def forward(self, student_output, teacher_output):\n",
        "        \"\"\"Evaluate loss.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        student_output, teacher_output : tuple\n",
        "            Tuple of tensors of shape `(n_samples, out_dim)` representing\n",
        "            logits. The length is equal to number of crops.\n",
        "            Note that student processed all crops and that the two initial crops\n",
        "            are the global ones.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        loss : torch.Tensor\n",
        "            Scalar representing the average loss.\n",
        "        \"\"\"\n",
        "        student_temp = [s / self.student_temp for s in student_output]\n",
        "        teacher_temp = [(t - self.center) / self.teacher_temp for t in teacher_output]\n",
        "\n",
        "        student_sm = [F.log_softmax(s, dim=-1) for s in student_temp]\n",
        "        teacher_sm = [F.softmax(t, dim=-1).detach() for t in teacher_temp]\n",
        "\n",
        "        total_loss = 0\n",
        "        n_loss_terms = 0\n",
        "\n",
        "        for t_ix, t in enumerate(teacher_sm):\n",
        "            for s_ix, s in enumerate(student_sm):\n",
        "                if t_ix == s_ix:\n",
        "                    continue\n",
        "\n",
        "                loss = torch.sum(-t * s, dim=-1)  # (n_samples,)\n",
        "                total_loss += loss.mean()  # scalar\n",
        "                n_loss_terms += 1\n",
        "\n",
        "        total_loss /= n_loss_terms\n",
        "        self.update_center(teacher_output)\n",
        "\n",
        "        return total_loss\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def update_center(self, teacher_output):\n",
        "        \"\"\"Update center used for teacher output.\n",
        "\n",
        "        Compute the exponential moving average.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        teacher_output : tuple\n",
        "            Tuple of tensors of shape `(n_samples, out_dim)` where each\n",
        "            tensor represents a different crop.\n",
        "        \"\"\"\n",
        "        batch_center = torch.cat(teacher_output).mean(\n",
        "            dim=0, keepdim=True\n",
        "        )  # (1, out_dim)\n",
        "        self.center = self.center * self.center_momentum + batch_center * (\n",
        "            1 - self.center_momentum\n",
        "        )\n",
        "\n",
        "\n",
        "def clip_gradients(model, clip=2.0):\n",
        "    \"\"\"Rescale norm of computed gradients.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model : nn.Module\n",
        "        Module.\n",
        "\n",
        "    clip : float\n",
        "        Maximum norm.\n",
        "    \"\"\"\n",
        "    for p in model.parameters():\n",
        "        if p.grad is not None:\n",
        "            param_norm = p.grad.data.norm(2)\n",
        "            clip_coef = clip / (param_norm + 1e-6)\n",
        "            if clip_coef < 1:\n",
        "                p.grad.data.mul_(clip_coef)\n",
        "\n",
        "def compute_knn(backbone, data_loader_train, data_loader_val):\n",
        "    \"\"\"Get CLS embeddings and use KNN classifier on them.\n",
        "\n",
        "    We load all embeddings in memory and use sklearn. Should\n",
        "    be doable.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    backbone : timm.models.vision_transformer.VisionTransformer\n",
        "        Vision transformer whose head is just an identity\n",
        "        mapping.\n",
        "\n",
        "    data_loader_train, data_loader_val : torch.utils.data.DataLoader\n",
        "        Training and validation dataloader that does not apply any\n",
        "        augmentations. Just casting to tensor and then normalizing.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    val_accuracy : float\n",
        "        Validation accuracy.\n",
        "    \"\"\"\n",
        "    device = next(backbone.parameters()).device\n",
        "\n",
        "    data_loaders = {\n",
        "        \"train\": data_loader_train,\n",
        "        \"val\": data_loader_val,\n",
        "    }\n",
        "    lists = {\n",
        "        \"X_train\": [],\n",
        "        \"y_train\": [],\n",
        "        \"X_val\": [],\n",
        "        \"y_val\": [],\n",
        "    }\n",
        "\n",
        "    for name, data_loader in data_loaders.items():\n",
        "        for imgs, y in data_loader:\n",
        "            imgs = imgs.to(device)\n",
        "            lists[f\"X_{name}\"].append(backbone(imgs).detach().cpu().numpy())\n",
        "            lists[f\"y_{name}\"].append(y.detach().cpu().numpy())\n",
        "\n",
        "    arrays = {k: np.concatenate(l) for k, l in lists.items()}\n",
        "\n",
        "    estimator = KNeighborsClassifier()\n",
        "    estimator.fit(arrays[\"X_train\"], arrays[\"y_train\"])\n",
        "    y_val_pred = estimator.predict(arrays[\"X_val\"])\n",
        "\n",
        "    acc = accuracy_score(arrays[\"y_val\"], y_val_pred)\n",
        "\n",
        "    return acc\n",
        "\n",
        "def compute_embedding(backbone, data_loader):\n",
        "    \"\"\"Compute CLS embedding and prepare for TensorBoard.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    backbone : timm.models.vision_transformer.VisionTransformer\n",
        "        Vision transformer. The head should be an identity mapping.\n",
        "\n",
        "    data_loader : torch.utils.data.DataLoader\n",
        "        Validation dataloader that does not apply any augmentations. Just\n",
        "        casting to tensor and then normalizing.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    embs : torch.Tensor\n",
        "        Embeddings of shape `(n_samples, out_dim)`.\n",
        "\n",
        "    imgs : torch.Tensor\n",
        "        Images of shape `(n_samples, 3, height, width)`.\n",
        "\n",
        "    labels : list\n",
        "        List of strings representing the classes.\n",
        "    \"\"\"\n",
        "    device = next(backbone.parameters()).device\n",
        "\n",
        "    embs_l = []\n",
        "    imgs_l = []\n",
        "    labels = []\n",
        "\n",
        "    for img, y in data_loader:\n",
        "        img = img.to(device)\n",
        "        embs_l.append(backbone(img).detach().cpu())\n",
        "        imgs_l.append(((img * 0.224) + 0.45).cpu())  # undo norm\n",
        "        labels.extend([data_loader.dataset.classes[i] for i in y.tolist()])\n",
        "\n",
        "    embs = torch.cat(embs_l, dim=0)\n",
        "    imgs = torch.cat(imgs_l, dim=0)\n",
        "\n",
        "    return embs, imgs, labels"
      ],
      "metadata": {
        "id": "avxFgEQ2ul0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "device = \"cuda\"\n",
        "logging_freq = 200\n",
        "n_crops = 4\n",
        "momentum_teacher = 0.995\n",
        "n_epochs  = 40\n",
        "dim = 1000\n",
        "out_dim = 1024\n",
        "clip_grad = 2.0\n",
        "norm_last_layer = True\n",
        "teacher_temp = 0.04\n",
        "student_temp = 0.1\n",
        "weight_decay = 0.4"
      ],
      "metadata": {
        "id": "nOzRMO1PuvDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform_aug = DataAugmentation(size=224, n_local_crops=n_crops - 2)\n",
        "dataset_train_aug = ImageFolder(path_dataset_train, transform=transform_aug)\n",
        "data_loader_train_aug = DataLoader(dataset_train_aug,batch_size=batch_size,shuffle=True,\n",
        "    drop_last=True,num_workers=n_workers, pin_memory=True,)"
      ],
      "metadata": {
        "id": "GvCD8SE9u2ej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "student_vit = torchvision.models.resnet18()\n",
        "teacher_vit = torchvision.models.resnet18()\n",
        "\n",
        "student = MultiCropWrapper(student_vit,Head(dim, out_dim, norm_last_layer=True, hidden_dim=512,bottleneck_dim=256,))\n",
        "\n",
        "teacher = MultiCropWrapper(teacher_vit, Head(dim, out_dim, norm_last_layer=True, hidden_dim=512,bottleneck_dim=256,))\n",
        "student, teacher = student.to(device), teacher.to(device)\n",
        "\n",
        "teacher.load_state_dict(student.state_dict())\n",
        "\n",
        "for p in teacher.parameters():\n",
        "        p.requires_grad = False"
      ],
      "metadata": {
        "id": "nl3Sk81ou7I4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss related\n",
        "loss_inst = Loss(out_dim, teacher_temp=teacher_temp,student_temp=student_temp,).to(device)\n",
        "\n",
        "lr = 0.001 * batch_size / 256\n",
        "optimizer = torch.optim.AdamW(student.parameters(),lr=lr,weight_decay=weight_decay)\n",
        "\n",
        "# Training loop\n",
        "n_batches = len(dataset_train_aug) //batch_size\n",
        "best_acc = 0\n",
        "n_steps = 0"
      ],
      "metadata": {
        "id": "fQ9zpB2pvIx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_best_path = '/content/gdrive/MyDrive/imagenette2-320/resnet_weights/best_model.pth'\n",
        "best_loss = 1e3"
      ],
      "metadata": {
        "id": "YlTO6iB6vPFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for e in range(n_epochs):\n",
        "    for i, (images, _) in tqdm.tqdm(enumerate(data_loader_train_aug), total=n_batches):\n",
        "\n",
        "        images = [img.to(device) for img in images]\n",
        "\n",
        "        teacher_output = teacher(images[:2])\n",
        "        student_output = student(images)\n",
        "\n",
        "        loss = loss_inst(student_output, teacher_output)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        clip_gradients(student, clip_grad)\n",
        "        optimizer.step()\n",
        "        if loss.item() < best_loss:\n",
        "          torch.save(student.state_dict(),save_best_path+ f'_str{e+100}.pth')\n",
        "          best_loss = loss.item()\n",
        "        if i%100 == 0:\n",
        "          print(f\"epoch : {e}  i : {i}  Loss : {loss.item()}\")\n",
        "        with torch.no_grad():\n",
        "            for student_ps, teacher_ps in zip(student.parameters(), teacher.parameters()):\n",
        "\n",
        "                teacher_ps.data.mul_(momentum_teacher)\n",
        "                teacher_ps.data.add_(\n",
        "                    (1 - momentum_teacher) * student_ps.detach().data\n",
        "                )\n",
        "        n_steps += 1\n",
        "\n",
        "    if e % 5 == 0:\n",
        "        save_path = f'/content/gdrive/MyDrive/imagenette2-320/resnet_weights/model_{e}.pth'\n",
        "        torch.save(student.state_dict(),save_path)\n",
        "        student.eval()\n",
        "        current_acc = compute_knn(student.backbone,data_loader_train_plain,data_loader_val_plain,)\n",
        "        print(f\"epoch :{e}  current_acc : {current_acc}\")\n",
        "        student.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "9QjD_CJevNcL",
        "outputId": "ac68eeb5-e7c2-433e-b8a7-e1771159df52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 1/147 [00:06<15:35,  6.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 0  i : 0  Loss : 8.49441146850586\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 69%|██████▊   | 101/147 [04:46<02:34,  3.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 0  i : 100  Loss : 8.991518020629883\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 147/147 [06:56<00:00,  2.83s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch :100  current_acc : 0.33203125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 1/147 [00:02<06:27,  2.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 1  i : 0  Loss : 8.986802101135254\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 69%|██████▊   | 101/147 [01:48<00:55,  1.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 1  i : 100  Loss : 8.98403549194336\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 147/147 [02:37<00:00,  1.07s/it]\n",
            "  1%|          | 1/147 [00:02<06:20,  2.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 2  i : 0  Loss : 8.968889236450195\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 69%|██████▊   | 101/147 [01:51<00:56,  1.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 2  i : 100  Loss : 8.92247200012207\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 147/147 [02:42<00:00,  1.10s/it]\n",
            "  1%|          | 1/147 [00:02<06:48,  2.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 3  i : 0  Loss : 8.899709701538086\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 8/147 [00:11<03:14,  1.40s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-91-9dc7c401f073>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mclip_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-73-96fb6d65a5ff>\u001b[0m in \u001b[0;36mclip_gradients\u001b[0;34m(model, clip)\u001b[0m\n\u001b[1;32m    364\u001b[0m             \u001b[0mparam_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m             \u001b[0mclip_coef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclip\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mparam_norm\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mclip_coef\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclip_coef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_path = '/content/gdrive/MyDrive/imagenette2-320/Resnet_weights/best_resnet_model.pth'\n",
        "student.load_state_dict(torch.load(best_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjKz9aEvw1Rp",
        "outputId": "2b099beb-359e-4219-8823-5d46e20983eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "student.eval()\n",
        "current_acc = compute_knn(student.backbone,data_loader_train_plain,data_loader_val_plain)\n",
        "student.train()\n",
        "print(f\"current_acc : {current_acc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "fYVSwR9Gx6VR",
        "outputId": "ff40d2b9-d8ba-4f00-8a54-fcd3129b675e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-118-d0902bd2be66>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstudent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcurrent_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_knn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_loader_train_plain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_loader_val_plain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mstudent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"current_acc : {current_acc}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-73-96fb6d65a5ff>\u001b[0m in \u001b[0;36mcompute_knn\u001b[0;34m(backbone, data_loader_train, data_loader_val)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_loaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m             \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0mlists\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf\"X_{name}\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1328\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1329\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1292\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1293\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1294\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1295\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1130\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1132\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1133\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class dino_resnet(nn.Module):\n",
        "\n",
        "    def __init__(self,num_classes,student,freeze):\n",
        "\n",
        "        super(dino_resnet, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.encoder = student.backbone\n",
        "\n",
        "        if freeze:\n",
        "          for p in self.encoder.parameters():\n",
        "            p.requires_grad = False\n",
        "        else:\n",
        "          for p in self.encoder.parameters():\n",
        "            p.requires_grad = True\n",
        "\n",
        "        self.activation = nn.ReLU()\n",
        "        self.classifier = nn.Linear(1000,num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.encoder(x)\n",
        "        x =  self.activation(x)\n",
        "        x = self.classifier(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "tF5gipMax9j-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available else \"cpu\")\n",
        "dino_model = dino_resnet(num_classes=10,student = student,freeze = False)\n",
        "# model = resnet(num_classes = 10)\n",
        "dino_model = dino_model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(dino_model.parameters(),lr = 0.001)"
      ],
      "metadata": {
        "id": "gC1MNXNoyArM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a_,b_,c_,d_ = train(data_loader_train_supervised,data_loader_test_supervised,dino_model,optimizer,criterion,50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyNTLssIyBNc",
        "outputId": "b8745e94-599b-406f-f19b-90cf20fc1a54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "idx : 0 , Current Loss(batch) : 2.309063673019409, Correct Predictions(batch) : 15/128\n",
            "idx : 5 , Current Loss(batch) : 1.6374412775039673, Correct Predictions(batch) : 79/128\n",
            "idx : 10 , Current Loss(batch) : 1.0436230897903442, Correct Predictions(batch) : 94/128\n",
            "Epoch: 0, Loss (per batch) : 1.5277, Accuracy: 0.5747\n",
            "Test Accuracy: 0.6102\n",
            "Average Test Loss : 1.2284\n",
            "idx : 0 , Current Loss(batch) : 0.7566370964050293, Correct Predictions(batch) : 97/128\n",
            "idx : 5 , Current Loss(batch) : 0.6162517666816711, Correct Predictions(batch) : 102/128\n",
            "idx : 10 , Current Loss(batch) : 0.4694118797779083, Correct Predictions(batch) : 107/128\n",
            "Epoch: 1, Loss (per batch) : 0.5575, Accuracy: 0.8146\n",
            "Test Accuracy: 0.5439\n",
            "Average Test Loss : 1.7321\n",
            "idx : 0 , Current Loss(batch) : 0.40690839290618896, Correct Predictions(batch) : 107/128\n",
            "idx : 5 , Current Loss(batch) : 0.29295873641967773, Correct Predictions(batch) : 118/128\n",
            "idx : 10 , Current Loss(batch) : 0.2980726361274719, Correct Predictions(batch) : 117/128\n",
            "Epoch: 2, Loss (per batch) : 0.3224, Accuracy: 0.8959\n",
            "Test Accuracy: 0.6395\n",
            "Average Test Loss : 1.4518\n",
            "idx : 0 , Current Loss(batch) : 0.20632612705230713, Correct Predictions(batch) : 119/128\n",
            "idx : 5 , Current Loss(batch) : 0.21864137053489685, Correct Predictions(batch) : 121/128\n",
            "idx : 10 , Current Loss(batch) : 0.2860313951969147, Correct Predictions(batch) : 114/128\n",
            "Epoch: 3, Loss (per batch) : 0.2211, Accuracy: 0.9255\n",
            "Test Accuracy: 0.6459\n",
            "Average Test Loss : 1.5515\n",
            "idx : 0 , Current Loss(batch) : 0.0713978037238121, Correct Predictions(batch) : 125/128\n",
            "idx : 5 , Current Loss(batch) : 0.20270875096321106, Correct Predictions(batch) : 120/128\n",
            "idx : 10 , Current Loss(batch) : 0.16927272081375122, Correct Predictions(batch) : 120/128\n",
            "Epoch: 4, Loss (per batch) : 0.1533, Accuracy: 0.9498\n",
            "Test Accuracy: 0.6713\n",
            "Average Test Loss : 1.3861\n",
            "idx : 0 , Current Loss(batch) : 0.07264780253171921, Correct Predictions(batch) : 125/128\n",
            "idx : 5 , Current Loss(batch) : 0.04264628514647484, Correct Predictions(batch) : 127/128\n",
            "idx : 10 , Current Loss(batch) : 0.06599557399749756, Correct Predictions(batch) : 125/128\n",
            "Epoch: 5, Loss (per batch) : 0.1072, Accuracy: 0.9651\n",
            "Test Accuracy: 0.7350\n",
            "Average Test Loss : 1.1823\n",
            "idx : 0 , Current Loss(batch) : 0.04892712086439133, Correct Predictions(batch) : 125/128\n",
            "idx : 5 , Current Loss(batch) : 0.17332823574543, Correct Predictions(batch) : 121/128\n",
            "idx : 10 , Current Loss(batch) : 0.038334790617227554, Correct Predictions(batch) : 127/128\n",
            "Epoch: 6, Loss (per batch) : 0.0777, Accuracy: 0.9768\n",
            "Test Accuracy: 0.7057\n",
            "Average Test Loss : 1.2576\n",
            "idx : 0 , Current Loss(batch) : 0.03172856569290161, Correct Predictions(batch) : 127/128\n",
            "idx : 5 , Current Loss(batch) : 0.13683874905109406, Correct Predictions(batch) : 126/128\n",
            "idx : 10 , Current Loss(batch) : 0.007416474632918835, Correct Predictions(batch) : 128/128\n",
            "Epoch: 7, Loss (per batch) : 0.0460, Accuracy: 0.9873\n",
            "Test Accuracy: 0.7134\n",
            "Average Test Loss : 1.3808\n",
            "idx : 0 , Current Loss(batch) : 0.017564646899700165, Correct Predictions(batch) : 127/128\n",
            "idx : 5 , Current Loss(batch) : 0.03623713552951813, Correct Predictions(batch) : 127/128\n",
            "idx : 10 , Current Loss(batch) : 0.026887277141213417, Correct Predictions(batch) : 127/128\n",
            "Epoch: 8, Loss (per batch) : 0.0376, Accuracy: 0.9878\n",
            "Test Accuracy: 0.7057\n",
            "Average Test Loss : 1.1817\n",
            "idx : 0 , Current Loss(batch) : 0.02807578817009926, Correct Predictions(batch) : 127/128\n",
            "idx : 5 , Current Loss(batch) : 0.039534792304039, Correct Predictions(batch) : 125/128\n",
            "idx : 10 , Current Loss(batch) : 0.026700148358941078, Correct Predictions(batch) : 127/128\n",
            "Epoch: 9, Loss (per batch) : 0.0385, Accuracy: 0.9878\n",
            "Test Accuracy: 0.7096\n",
            "Average Test Loss : 1.5148\n",
            "idx : 0 , Current Loss(batch) : 0.017810365185141563, Correct Predictions(batch) : 127/128\n",
            "idx : 5 , Current Loss(batch) : 0.025637006387114525, Correct Predictions(batch) : 127/128\n",
            "idx : 10 , Current Loss(batch) : 0.020304515957832336, Correct Predictions(batch) : 127/128\n",
            "Epoch: 10, Loss (per batch) : 0.0466, Accuracy: 0.9857\n",
            "Test Accuracy: 0.7096\n",
            "Average Test Loss : 1.3618\n",
            "idx : 0 , Current Loss(batch) : 0.019009752199053764, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.005947597324848175, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.04271122068166733, Correct Predictions(batch) : 125/128\n",
            "Epoch: 11, Loss (per batch) : 0.0466, Accuracy: 0.9884\n",
            "Test Accuracy: 0.6306\n",
            "Average Test Loss : 1.7007\n",
            "idx : 0 , Current Loss(batch) : 0.042833082377910614, Correct Predictions(batch) : 125/128\n",
            "idx : 5 , Current Loss(batch) : 0.1036500558257103, Correct Predictions(batch) : 123/128\n",
            "idx : 10 , Current Loss(batch) : 0.045044977217912674, Correct Predictions(batch) : 127/128\n",
            "Epoch: 12, Loss (per batch) : 0.0648, Accuracy: 0.9762\n",
            "Test Accuracy: 0.7389\n",
            "Average Test Loss : 1.1872\n",
            "idx : 0 , Current Loss(batch) : 0.023719727993011475, Correct Predictions(batch) : 127/128\n",
            "idx : 5 , Current Loss(batch) : 0.06270231306552887, Correct Predictions(batch) : 125/128\n",
            "idx : 10 , Current Loss(batch) : 0.05838550627231598, Correct Predictions(batch) : 126/128\n",
            "Epoch: 13, Loss (per batch) : 0.0795, Accuracy: 0.9762\n",
            "Test Accuracy: 0.5732\n",
            "Average Test Loss : 2.2984\n",
            "idx : 0 , Current Loss(batch) : 0.02690875716507435, Correct Predictions(batch) : 127/128\n",
            "idx : 5 , Current Loss(batch) : 0.051294200122356415, Correct Predictions(batch) : 127/128\n",
            "idx : 10 , Current Loss(batch) : 0.08763478696346283, Correct Predictions(batch) : 123/128\n",
            "Epoch: 14, Loss (per batch) : 0.0862, Accuracy: 0.9757\n",
            "Test Accuracy: 0.6688\n",
            "Average Test Loss : 1.6054\n",
            "idx : 0 , Current Loss(batch) : 0.03262440487742424, Correct Predictions(batch) : 127/128\n",
            "idx : 5 , Current Loss(batch) : 0.09876390546560287, Correct Predictions(batch) : 122/128\n",
            "idx : 10 , Current Loss(batch) : 0.1744217574596405, Correct Predictions(batch) : 122/128\n",
            "Epoch: 15, Loss (per batch) : 0.0756, Accuracy: 0.9794\n",
            "Test Accuracy: 0.6000\n",
            "Average Test Loss : 2.5432\n",
            "idx : 0 , Current Loss(batch) : 0.043805018067359924, Correct Predictions(batch) : 126/128\n",
            "idx : 5 , Current Loss(batch) : 0.2685815989971161, Correct Predictions(batch) : 120/128\n",
            "idx : 10 , Current Loss(batch) : 0.1139373779296875, Correct Predictions(batch) : 123/128\n",
            "Epoch: 16, Loss (per batch) : 0.0858, Accuracy: 0.9746\n",
            "Test Accuracy: 0.7185\n",
            "Average Test Loss : 1.6006\n",
            "idx : 0 , Current Loss(batch) : 0.036756888031959534, Correct Predictions(batch) : 126/128\n",
            "idx : 5 , Current Loss(batch) : 0.04548144340515137, Correct Predictions(batch) : 127/128\n",
            "idx : 10 , Current Loss(batch) : 0.10616246610879898, Correct Predictions(batch) : 126/128\n",
            "Epoch: 17, Loss (per batch) : 0.0768, Accuracy: 0.9778\n",
            "Test Accuracy: 0.5376\n",
            "Average Test Loss : 2.4092\n",
            "idx : 0 , Current Loss(batch) : 0.06049889698624611, Correct Predictions(batch) : 125/128\n",
            "idx : 5 , Current Loss(batch) : 0.02070462517440319, Correct Predictions(batch) : 127/128\n",
            "idx : 10 , Current Loss(batch) : 0.044129904359579086, Correct Predictions(batch) : 127/128\n",
            "Epoch: 18, Loss (per batch) : 0.0616, Accuracy: 0.9799\n",
            "Test Accuracy: 0.7146\n",
            "Average Test Loss : 1.2554\n",
            "idx : 0 , Current Loss(batch) : 0.04742726683616638, Correct Predictions(batch) : 127/128\n",
            "idx : 5 , Current Loss(batch) : 0.033294305205345154, Correct Predictions(batch) : 127/128\n",
            "idx : 10 , Current Loss(batch) : 0.059122055768966675, Correct Predictions(batch) : 125/128\n",
            "Epoch: 19, Loss (per batch) : 0.0357, Accuracy: 0.9878\n",
            "Test Accuracy: 0.7248\n",
            "Average Test Loss : 1.3414\n",
            "idx : 0 , Current Loss(batch) : 0.006214939057826996, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.07954790443181992, Correct Predictions(batch) : 127/128\n",
            "idx : 10 , Current Loss(batch) : 0.016269592568278313, Correct Predictions(batch) : 127/128\n",
            "Epoch: 20, Loss (per batch) : 0.0409, Accuracy: 0.9894\n",
            "Test Accuracy: 0.7414\n",
            "Average Test Loss : 1.5102\n",
            "idx : 0 , Current Loss(batch) : 0.052989836782217026, Correct Predictions(batch) : 126/128\n",
            "idx : 5 , Current Loss(batch) : 0.014945251867175102, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.003206410212442279, Correct Predictions(batch) : 128/128\n",
            "Epoch: 21, Loss (per batch) : 0.0255, Accuracy: 0.9905\n",
            "Test Accuracy: 0.7401\n",
            "Average Test Loss : 1.0626\n",
            "idx : 0 , Current Loss(batch) : 0.016697606071829796, Correct Predictions(batch) : 127/128\n",
            "idx : 5 , Current Loss(batch) : 0.05228534713387489, Correct Predictions(batch) : 127/128\n",
            "idx : 10 , Current Loss(batch) : 0.12710396945476532, Correct Predictions(batch) : 124/128\n",
            "Epoch: 22, Loss (per batch) : 0.0318, Accuracy: 0.9931\n",
            "Test Accuracy: 0.6930\n",
            "Average Test Loss : 1.4801\n",
            "idx : 0 , Current Loss(batch) : 0.005546352826058865, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.029285963624715805, Correct Predictions(batch) : 127/128\n",
            "idx : 10 , Current Loss(batch) : 0.015068095177412033, Correct Predictions(batch) : 127/128\n",
            "Epoch: 23, Loss (per batch) : 0.0234, Accuracy: 0.9926\n",
            "Test Accuracy: 0.7210\n",
            "Average Test Loss : 1.3560\n",
            "idx : 0 , Current Loss(batch) : 0.0023139871191233397, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.003438197076320648, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.019758982583880424, Correct Predictions(batch) : 127/128\n",
            "Epoch: 24, Loss (per batch) : 0.0119, Accuracy: 0.9958\n",
            "Test Accuracy: 0.7134\n",
            "Average Test Loss : 1.4098\n",
            "idx : 0 , Current Loss(batch) : 0.0022143758833408356, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.0019019863102585077, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.002216296037659049, Correct Predictions(batch) : 128/128\n",
            "Epoch: 25, Loss (per batch) : 0.0096, Accuracy: 0.9984\n",
            "Test Accuracy: 0.7707\n",
            "Average Test Loss : 1.2226\n",
            "idx : 0 , Current Loss(batch) : 0.008124691434204578, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.005749768111854792, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.001315150992013514, Correct Predictions(batch) : 128/128\n",
            "Epoch: 26, Loss (per batch) : 0.0048, Accuracy: 0.9995\n",
            "Test Accuracy: 0.8000\n",
            "Average Test Loss : 0.9034\n",
            "idx : 0 , Current Loss(batch) : 0.0014595913235098124, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.001335144741460681, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.01628388650715351, Correct Predictions(batch) : 127/128\n",
            "Epoch: 27, Loss (per batch) : 0.0033, Accuracy: 0.9989\n",
            "Test Accuracy: 0.8038\n",
            "Average Test Loss : 0.8941\n",
            "idx : 0 , Current Loss(batch) : 0.0019100150093436241, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.0011101668933406472, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.0016402096953243017, Correct Predictions(batch) : 128/128\n",
            "Epoch: 28, Loss (per batch) : 0.0015, Accuracy: 1.0000\n",
            "Test Accuracy: 0.7962\n",
            "Average Test Loss : 0.9275\n",
            "idx : 0 , Current Loss(batch) : 0.00024260008649434894, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.0004013373691122979, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.0003723848203662783, Correct Predictions(batch) : 128/128\n",
            "Epoch: 29, Loss (per batch) : 0.0005, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8025\n",
            "Average Test Loss : 0.9165\n",
            "idx : 0 , Current Loss(batch) : 0.000348715198924765, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.0005980833666399121, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.00016516770119778812, Correct Predictions(batch) : 128/128\n",
            "Epoch: 30, Loss (per batch) : 0.0005, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8102\n",
            "Average Test Loss : 0.8438\n",
            "idx : 0 , Current Loss(batch) : 0.0002954818191938102, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.0003670100122690201, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.002098826225847006, Correct Predictions(batch) : 128/128\n",
            "Epoch: 31, Loss (per batch) : 0.0003, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8102\n",
            "Average Test Loss : 0.8779\n",
            "idx : 0 , Current Loss(batch) : 0.00010497529001440853, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 9.646960097597912e-05, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.00011936366354348138, Correct Predictions(batch) : 128/128\n",
            "Epoch: 32, Loss (per batch) : 0.0002, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8153\n",
            "Average Test Loss : 0.8486\n",
            "idx : 0 , Current Loss(batch) : 0.00019761419389396906, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.00018298627401236445, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.00038394820876419544, Correct Predictions(batch) : 128/128\n",
            "Epoch: 33, Loss (per batch) : 0.0002, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8178\n",
            "Average Test Loss : 0.7977\n",
            "idx : 0 , Current Loss(batch) : 7.480733620468527e-05, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.00010005982767324895, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.00020978999964427203, Correct Predictions(batch) : 128/128\n",
            "Epoch: 34, Loss (per batch) : 0.0001, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8178\n",
            "Average Test Loss : 0.9551\n",
            "idx : 0 , Current Loss(batch) : 5.4375865147449076e-05, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.0003703420516103506, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.00025270297192037106, Correct Predictions(batch) : 128/128\n",
            "Epoch: 35, Loss (per batch) : 0.0003, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8191\n",
            "Average Test Loss : 0.7887\n",
            "idx : 0 , Current Loss(batch) : 5.265419167699292e-05, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 8.908509335014969e-05, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 6.293504702625796e-05, Correct Predictions(batch) : 128/128\n",
            "Epoch: 36, Loss (per batch) : 0.0001, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8191\n",
            "Average Test Loss : 0.8747\n",
            "idx : 0 , Current Loss(batch) : 0.0001275808026548475, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 4.7506229748250917e-05, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.00018330937018617988, Correct Predictions(batch) : 128/128\n",
            "Epoch: 37, Loss (per batch) : 0.0001, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8166\n",
            "Average Test Loss : 0.8476\n",
            "idx : 0 , Current Loss(batch) : 0.0001260945136891678, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.00012737854558508843, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 7.45249490137212e-05, Correct Predictions(batch) : 128/128\n",
            "Epoch: 38, Loss (per batch) : 0.0001, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8166\n",
            "Average Test Loss : 0.8748\n",
            "idx : 0 , Current Loss(batch) : 4.843315764446743e-05, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.00010679009574232623, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 4.859446926275268e-05, Correct Predictions(batch) : 128/128\n",
            "Epoch: 39, Loss (per batch) : 0.0001, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8166\n",
            "Average Test Loss : 0.9501\n",
            "idx : 0 , Current Loss(batch) : 0.00010387032671133056, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 4.150558015680872e-05, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 6.433555972762406e-05, Correct Predictions(batch) : 128/128\n",
            "Epoch: 40, Loss (per batch) : 0.0001, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8191\n",
            "Average Test Loss : 0.8354\n",
            "idx : 0 , Current Loss(batch) : 4.233916843077168e-05, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 5.026800135965459e-05, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 7.4773131927941e-05, Correct Predictions(batch) : 128/128\n",
            "Epoch: 41, Loss (per batch) : 0.0001, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8217\n",
            "Average Test Loss : 0.8377\n",
            "idx : 0 , Current Loss(batch) : 7.886828825576231e-05, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 5.636770947603509e-05, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 4.515948239713907e-05, Correct Predictions(batch) : 128/128\n",
            "Epoch: 42, Loss (per batch) : 0.0001, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8204\n",
            "Average Test Loss : 0.8405\n",
            "idx : 0 , Current Loss(batch) : 0.00011834927136078477, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 5.922068521613255e-05, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 3.968360397266224e-05, Correct Predictions(batch) : 128/128\n",
            "Epoch: 43, Loss (per batch) : 0.0001, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8229\n",
            "Average Test Loss : 0.8195\n",
            "idx : 0 , Current Loss(batch) : 4.942734449286945e-05, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 8.714674913790077e-05, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 5.037729715695605e-05, Correct Predictions(batch) : 128/128\n",
            "Epoch: 44, Loss (per batch) : 0.0001, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8191\n",
            "Average Test Loss : 0.9503\n",
            "idx : 0 , Current Loss(batch) : 2.8905797080369666e-05, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 6.235446926439181e-05, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 5.9764723118860275e-05, Correct Predictions(batch) : 128/128\n",
            "Epoch: 45, Loss (per batch) : 0.0001, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8191\n",
            "Average Test Loss : 0.8405\n",
            "idx : 0 , Current Loss(batch) : 5.2068528020754457e-05, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 9.070078522199765e-05, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 3.368445686646737e-05, Correct Predictions(batch) : 128/128\n",
            "Epoch: 46, Loss (per batch) : 0.0001, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8166\n",
            "Average Test Loss : 0.8829\n",
            "idx : 0 , Current Loss(batch) : 4.591955803334713e-05, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 4.8466146836290136e-05, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 2.2151885787025094e-05, Correct Predictions(batch) : 128/128\n",
            "Epoch: 47, Loss (per batch) : 0.0001, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8217\n",
            "Average Test Loss : 0.8498\n",
            "idx : 0 , Current Loss(batch) : 7.733265374554321e-05, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 4.731664739665575e-05, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 4.708669439423829e-05, Correct Predictions(batch) : 128/128\n",
            "Epoch: 48, Loss (per batch) : 0.0001, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8217\n",
            "Average Test Loss : 0.9870\n",
            "idx : 0 , Current Loss(batch) : 4.085389446117915e-05, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 3.224949978175573e-05, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 4.402643389767036e-05, Correct Predictions(batch) : 128/128\n",
            "Epoch: 49, Loss (per batch) : 0.0001, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8217\n",
            "Average Test Loss : 0.9802\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available else \"cpu\")\n",
        "dino_model = dino_resnet(num_classes=10,student = student,freeze = True)\n",
        "# model = resnet(num_classes = 10)\n",
        "dino_model = dino_model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(dino_model.parameters(),lr = 0.001)"
      ],
      "metadata": {
        "id": "BRzGvF2T4oiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a1_,b1_,c1_,d1_ = train(data_loader_train_supervised,data_loader_test_supervised,dino_model,optimizer,criterion,50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hFgvsZ77z3G",
        "outputId": "7ee9b7b9-17c7-460c-e324-0c444f93df0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "idx : 0 , Current Loss(batch) : 2.5271718502044678, Correct Predictions(batch) : 2/128\n",
            "idx : 5 , Current Loss(batch) : 0.855148196220398, Correct Predictions(batch) : 127/128\n",
            "idx : 10 , Current Loss(batch) : 0.2452448010444641, Correct Predictions(batch) : 128/128\n",
            "Epoch: 0, Loss (per batch) : 0.8205, Accuracy: 0.8685\n",
            "Test Accuracy: 0.8115\n",
            "Average Test Loss : 0.6565\n",
            "idx : 0 , Current Loss(batch) : 0.0667416974902153, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.040391165763139725, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.022342432290315628, Correct Predictions(batch) : 128/128\n",
            "Epoch: 1, Loss (per batch) : 0.0376, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8115\n",
            "Average Test Loss : 0.6522\n",
            "idx : 0 , Current Loss(batch) : 0.024831531569361687, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.013432176783680916, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.010921841487288475, Correct Predictions(batch) : 128/128\n",
            "Epoch: 2, Loss (per batch) : 0.0135, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8153\n",
            "Average Test Loss : 0.6138\n",
            "idx : 0 , Current Loss(batch) : 0.008339240215718746, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.008302287198603153, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.00826274324208498, Correct Predictions(batch) : 128/128\n",
            "Epoch: 3, Loss (per batch) : 0.0100, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8153\n",
            "Average Test Loss : 0.5947\n",
            "idx : 0 , Current Loss(batch) : 0.007091414649039507, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.009768822230398655, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.007181616500020027, Correct Predictions(batch) : 128/128\n",
            "Epoch: 4, Loss (per batch) : 0.0080, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8153\n",
            "Average Test Loss : 0.6248\n",
            "idx : 0 , Current Loss(batch) : 0.007631146349012852, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.007331877946853638, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.00558189582079649, Correct Predictions(batch) : 128/128\n",
            "Epoch: 5, Loss (per batch) : 0.0071, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8166\n",
            "Average Test Loss : 0.6184\n",
            "idx : 0 , Current Loss(batch) : 0.005410133395344019, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.004028359893709421, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.0063023860566318035, Correct Predictions(batch) : 128/128\n",
            "Epoch: 6, Loss (per batch) : 0.0059, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8140\n",
            "Average Test Loss : 0.5616\n",
            "idx : 0 , Current Loss(batch) : 0.004173068795353174, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.006271338555961847, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.005336276721209288, Correct Predictions(batch) : 128/128\n",
            "Epoch: 7, Loss (per batch) : 0.0051, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8166\n",
            "Average Test Loss : 0.6047\n",
            "idx : 0 , Current Loss(batch) : 0.003877201583236456, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.00524526322260499, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.004627903923392296, Correct Predictions(batch) : 128/128\n",
            "Epoch: 8, Loss (per batch) : 0.0055, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8127\n",
            "Average Test Loss : 0.6332\n",
            "idx : 0 , Current Loss(batch) : 0.0049690674059093, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.003494562581181526, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.005368815269321203, Correct Predictions(batch) : 128/128\n",
            "Epoch: 9, Loss (per batch) : 0.0046, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8153\n",
            "Average Test Loss : 0.6524\n",
            "idx : 0 , Current Loss(batch) : 0.004991712048649788, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.003412497928366065, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.004020066931843758, Correct Predictions(batch) : 128/128\n",
            "Epoch: 10, Loss (per batch) : 0.0045, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8166\n",
            "Average Test Loss : 0.6519\n",
            "idx : 0 , Current Loss(batch) : 0.005037732422351837, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.003530951216816902, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.0038077994249761105, Correct Predictions(batch) : 128/128\n",
            "Epoch: 11, Loss (per batch) : 0.0041, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8140\n",
            "Average Test Loss : 0.5721\n",
            "idx : 0 , Current Loss(batch) : 0.00295154913328588, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.0050923507660627365, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.002544563263654709, Correct Predictions(batch) : 128/128\n",
            "Epoch: 12, Loss (per batch) : 0.0039, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8140\n",
            "Average Test Loss : 0.6311\n",
            "idx : 0 , Current Loss(batch) : 0.00346594350412488, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.0028204035479575396, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.003357043256983161, Correct Predictions(batch) : 128/128\n",
            "Epoch: 13, Loss (per batch) : 0.0034, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8178\n",
            "Average Test Loss : 0.6827\n",
            "idx : 0 , Current Loss(batch) : 0.0029611345380544662, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.00322561408393085, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.003141687950119376, Correct Predictions(batch) : 128/128\n",
            "Epoch: 14, Loss (per batch) : 0.0031, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8166\n",
            "Average Test Loss : 0.5733\n",
            "idx : 0 , Current Loss(batch) : 0.0027064078021794558, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.003098584245890379, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.004381874576210976, Correct Predictions(batch) : 128/128\n",
            "Epoch: 15, Loss (per batch) : 0.0028, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8153\n",
            "Average Test Loss : 0.6664\n",
            "idx : 0 , Current Loss(batch) : 0.002687095431610942, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.0028673929627984762, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.002656023483723402, Correct Predictions(batch) : 128/128\n",
            "Epoch: 16, Loss (per batch) : 0.0026, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8153\n",
            "Average Test Loss : 0.6237\n",
            "idx : 0 , Current Loss(batch) : 0.002217754954472184, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.0024940206203609705, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.0033954994287341833, Correct Predictions(batch) : 128/128\n",
            "Epoch: 17, Loss (per batch) : 0.0025, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8178\n",
            "Average Test Loss : 0.7592\n",
            "idx : 0 , Current Loss(batch) : 0.0020964182913303375, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.0019195445347577333, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.002757762325927615, Correct Predictions(batch) : 128/128\n",
            "Epoch: 18, Loss (per batch) : 0.0024, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8166\n",
            "Average Test Loss : 0.6846\n",
            "idx : 0 , Current Loss(batch) : 0.001936415326781571, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.0044530415907502174, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.0024452628567814827, Correct Predictions(batch) : 128/128\n",
            "Epoch: 19, Loss (per batch) : 0.0026, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8178\n",
            "Average Test Loss : 0.6873\n",
            "idx : 0 , Current Loss(batch) : 0.003379120258614421, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.0019801573362201452, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.001890990068204701, Correct Predictions(batch) : 128/128\n",
            "Epoch: 20, Loss (per batch) : 0.0022, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8191\n",
            "Average Test Loss : 0.6141\n",
            "idx : 0 , Current Loss(batch) : 0.0018842107383534312, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.001737609738484025, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.0016548173734918237, Correct Predictions(batch) : 128/128\n",
            "Epoch: 21, Loss (per batch) : 0.0019, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8153\n",
            "Average Test Loss : 0.5663\n",
            "idx : 0 , Current Loss(batch) : 0.0013313814997673035, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.0018028364283964038, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.0017011004965752363, Correct Predictions(batch) : 128/128\n",
            "Epoch: 22, Loss (per batch) : 0.0018, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8166\n",
            "Average Test Loss : 0.6768\n",
            "idx : 0 , Current Loss(batch) : 0.0019297143444418907, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.0017895869677886367, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.0014430541777983308, Correct Predictions(batch) : 128/128\n",
            "Epoch: 23, Loss (per batch) : 0.0018, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8178\n",
            "Average Test Loss : 0.6373\n",
            "idx : 0 , Current Loss(batch) : 0.001963975839316845, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.0012282314710319042, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.0022004868369549513, Correct Predictions(batch) : 128/128\n",
            "Epoch: 24, Loss (per batch) : 0.0017, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8153\n",
            "Average Test Loss : 0.7027\n",
            "idx : 0 , Current Loss(batch) : 0.00247346144169569, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.0015940709272399545, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.0023764155339449644, Correct Predictions(batch) : 128/128\n",
            "Epoch: 25, Loss (per batch) : 0.0017, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8166\n",
            "Average Test Loss : 0.6878\n",
            "idx : 0 , Current Loss(batch) : 0.001466628280468285, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.001921380404382944, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.0013328330824151635, Correct Predictions(batch) : 128/128\n",
            "Epoch: 26, Loss (per batch) : 0.0016, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8140\n",
            "Average Test Loss : 0.6789\n",
            "idx : 0 , Current Loss(batch) : 0.001086098956875503, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.0016624784329906106, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.0018260820070281625, Correct Predictions(batch) : 128/128\n",
            "Epoch: 27, Loss (per batch) : 0.0016, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8204\n",
            "Average Test Loss : 0.6173\n",
            "idx : 0 , Current Loss(batch) : 0.0013138492358848453, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.0009632584406062961, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.0014580573188140988, Correct Predictions(batch) : 128/128\n",
            "Epoch: 28, Loss (per batch) : 0.0016, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8229\n",
            "Average Test Loss : 0.6228\n",
            "idx : 0 , Current Loss(batch) : 0.001166659640148282, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.001127161318436265, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.0019535168539732695, Correct Predictions(batch) : 128/128\n",
            "Epoch: 29, Loss (per batch) : 0.0015, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8166\n",
            "Average Test Loss : 0.7149\n",
            "idx : 0 , Current Loss(batch) : 0.0011690391693264246, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.0008714565192349255, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.0011458086082711816, Correct Predictions(batch) : 128/128\n",
            "Epoch: 30, Loss (per batch) : 0.0012, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8153\n",
            "Average Test Loss : 0.6935\n",
            "idx : 0 , Current Loss(batch) : 0.0011565989116206765, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.000945526931900531, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.0013282804284244776, Correct Predictions(batch) : 128/128\n",
            "Epoch: 31, Loss (per batch) : 0.0013, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8178\n",
            "Average Test Loss : 0.7028\n",
            "idx : 0 , Current Loss(batch) : 0.000978156691417098, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.0010921657085418701, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.0006817873800173402, Correct Predictions(batch) : 128/128\n",
            "Epoch: 32, Loss (per batch) : 0.0012, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8166\n",
            "Average Test Loss : 0.7317\n",
            "idx : 0 , Current Loss(batch) : 0.0008572406368330121, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.0016523355152457952, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.000867322669364512, Correct Predictions(batch) : 128/128\n",
            "Epoch: 33, Loss (per batch) : 0.0011, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8153\n",
            "Average Test Loss : 0.6406\n",
            "idx : 0 , Current Loss(batch) : 0.0010085211833938956, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.0007807326037436724, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.0019043025095015764, Correct Predictions(batch) : 128/128\n",
            "Epoch: 34, Loss (per batch) : 0.0011, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8178\n",
            "Average Test Loss : 0.6696\n",
            "idx : 0 , Current Loss(batch) : 0.0014429549919441342, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.0018205365631729364, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.0006740912795066833, Correct Predictions(batch) : 128/128\n",
            "Epoch: 35, Loss (per batch) : 0.0011, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8153\n",
            "Average Test Loss : 0.6207\n",
            "idx : 0 , Current Loss(batch) : 0.0007961838855408132, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.0007124369731172919, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.0014234725385904312, Correct Predictions(batch) : 128/128\n",
            "Epoch: 36, Loss (per batch) : 0.0011, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8153\n",
            "Average Test Loss : 0.6263\n",
            "idx : 0 , Current Loss(batch) : 0.0009401931893080473, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.0008047819137573242, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.0009562263148836792, Correct Predictions(batch) : 128/128\n",
            "Epoch: 37, Loss (per batch) : 0.0009, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8166\n",
            "Average Test Loss : 0.6837\n",
            "idx : 0 , Current Loss(batch) : 0.000740236893761903, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.000917367753572762, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.0006560971960425377, Correct Predictions(batch) : 128/128\n",
            "Epoch: 38, Loss (per batch) : 0.0010, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8127\n",
            "Average Test Loss : 0.6753\n",
            "idx : 0 , Current Loss(batch) : 0.0006007838528603315, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.0006234677857719362, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.0009542796760797501, Correct Predictions(batch) : 128/128\n",
            "Epoch: 39, Loss (per batch) : 0.0010, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8166\n",
            "Average Test Loss : 0.7275\n",
            "idx : 0 , Current Loss(batch) : 0.0006535809370689094, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.0011058143572881818, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.0012247819686308503, Correct Predictions(batch) : 128/128\n",
            "Epoch: 40, Loss (per batch) : 0.0009, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8166\n",
            "Average Test Loss : 0.7038\n",
            "idx : 0 , Current Loss(batch) : 0.0011901844991371036, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.0007409713580273092, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.0005948375910520554, Correct Predictions(batch) : 128/128\n",
            "Epoch: 41, Loss (per batch) : 0.0009, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8166\n",
            "Average Test Loss : 0.7149\n",
            "idx : 0 , Current Loss(batch) : 0.0006946393987163901, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.0007621700060553849, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.0010333580430597067, Correct Predictions(batch) : 128/128\n",
            "Epoch: 42, Loss (per batch) : 0.0008, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8178\n",
            "Average Test Loss : 0.7592\n",
            "idx : 0 , Current Loss(batch) : 0.0006380482809618115, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.000954346964135766, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.0011031077010557055, Correct Predictions(batch) : 128/128\n",
            "Epoch: 43, Loss (per batch) : 0.0008, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8178\n",
            "Average Test Loss : 0.6738\n",
            "idx : 0 , Current Loss(batch) : 0.0007826281362213194, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.0010304991155862808, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.000768175523262471, Correct Predictions(batch) : 128/128\n",
            "Epoch: 44, Loss (per batch) : 0.0008, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8127\n",
            "Average Test Loss : 0.6768\n",
            "idx : 0 , Current Loss(batch) : 0.0004572151810862124, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.0006656881305389106, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.0013147784629836679, Correct Predictions(batch) : 128/128\n",
            "Epoch: 45, Loss (per batch) : 0.0008, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8153\n",
            "Average Test Loss : 0.7546\n",
            "idx : 0 , Current Loss(batch) : 0.0007447171374224126, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.0006621615611948073, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.0010826516663655639, Correct Predictions(batch) : 128/128\n",
            "Epoch: 46, Loss (per batch) : 0.0008, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8127\n",
            "Average Test Loss : 0.7778\n",
            "idx : 0 , Current Loss(batch) : 0.00030497723491862416, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.0005016819923184812, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.0005115335225127637, Correct Predictions(batch) : 128/128\n",
            "Epoch: 47, Loss (per batch) : 0.0007, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8140\n",
            "Average Test Loss : 0.6385\n",
            "idx : 0 , Current Loss(batch) : 0.0006641845684498549, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.0004903977969661355, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.0007456311141140759, Correct Predictions(batch) : 128/128\n",
            "Epoch: 48, Loss (per batch) : 0.0008, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8153\n",
            "Average Test Loss : 0.6705\n",
            "idx : 0 , Current Loss(batch) : 0.00046241647214628756, Correct Predictions(batch) : 128/128\n",
            "idx : 5 , Current Loss(batch) : 0.000594157783780247, Correct Predictions(batch) : 128/128\n",
            "idx : 10 , Current Loss(batch) : 0.0006057380815036595, Correct Predictions(batch) : 128/128\n",
            "Epoch: 49, Loss (per batch) : 0.0007, Accuracy: 1.0000\n",
            "Test Accuracy: 0.8140\n",
            "Average Test Loss : 0.6340\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.save(f'/content/gdrive/MyDrive/imagenette2-320/Resnet_weights/a_.npy',a_)\n",
        "np.save(f'/content/gdrive/MyDrive/imagenette2-320/Resnet_weights/b_.npy',b_)\n",
        "np.save(f'/content/gdrive/MyDrive/imagenette2-320/Resnet_weights/c_.npy',c_)\n",
        "np.save(f'/content/gdrive/MyDrive/imagenette2-320/Resnet_weights/d_.npy',d_)\n",
        "np.save(f'/content/gdrive/MyDrive/imagenette2-320/Resnet_weights/a1_.npy',a1_)\n",
        "np.save(f'/content/gdrive/MyDrive/imagenette2-320/Resnet_weights/b1_.npy',b1_)\n",
        "np.save(f'/content/gdrive/MyDrive/imagenette2-320/Resnet_weights/c1_.npy',c1_)\n",
        "np.save(f'/content/gdrive/MyDrive/imagenette2-320/Resnet_weights/d1_.npy',d1_)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3CDN9mUS75cA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save(f'/content/gdrive/MyDrive/imagenette2-320/Resnet_weights/a.npy',a)\n",
        "np.save(f'/content/gdrive/MyDrive/imagenette2-320/Resnet_weights/b.npy',b)\n",
        "np.save(f'/content/gdrive/MyDrive/imagenette2-320/Resnet_weights/c.npy',c)\n",
        "np.save(f'/content/gdrive/MyDrive/imagenette2-320/Resnet_weights/d.npy',d)\n"
      ],
      "metadata": {
        "id": "gO4S3PpC9CAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save(f'/content/gdrive/MyDrive/imagenette2-320/Resnet_weights/a1.npy',a1)\n",
        "np.save(f'/content/gdrive/MyDrive/imagenette2-320/Resnet_weights/b1.npy',b1)\n",
        "np.save(f'/content/gdrive/MyDrive/imagenette2-320/Resnet_weights/c1.npy',c1)\n",
        "np.save(f'/content/gdrive/MyDrive/imagenette2-320/Resnet_weights/d1.npy',d1)\n"
      ],
      "metadata": {
        "id": "kbd_QQZj-NbW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}