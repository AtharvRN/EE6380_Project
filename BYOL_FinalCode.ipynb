{"cells":[{"cell_type":"markdown","metadata":{},"source":["# BYOL PyTorch\n","BYOL implementation using PyTorch\n","Main Reference: Bootstrap Your Own Latent: A New Approach to Self-Supervised Learning https://arxiv.org/abs/2006.07733\n","\n","Main part of the code is inspired from https://github.com/reshinthadithyan/BYOL-Pytorch, and https://github.com/google-deepmind/deepmind-research/tree/master/byol"]},{"cell_type":"markdown","metadata":{},"source":["## Default Training"]},{"cell_type":"markdown","metadata":{},"source":["### Data Augmentations"]},{"cell_type":"markdown","metadata":{},"source":["* Random cropping\n","* Optional left-right flip **Optional**\n","* Color jittering -> brightness, contrast, saturation, hue -> shifted by a random offset, applied on all pixels of the image, the order in which these shifts are performed is randomly selected for each patch.\n","* Color dropping -> Conversion to gray scale\n","* Gaussian blurring -> **Optional** for a 224 x 224 image, a square Gaussian kernel of size 23 x 23 is used, with a standard deviation uniformly sampled  over `[0.1,2.0]`\n","* Solarization -> **Optional** `x -> x*1{x<0.5} + (1-x)*1{x>=0.5}` for pixel with values in `[0,1]`\n","    * Solarization not implemented in actual code implementation"]},{"cell_type":"markdown","metadata":{},"source":["* **Also while applying Gaussian Blur, Gaussian Blur function is not directly used**.\n","* **Instead, conv2d is used where `3 channels, 3 kernels, kernel size = (kernel_size,1) and (1,kernel_size), and no bias, no padding, stride = 1, groups = 3`**"]},{"cell_type":"markdown","metadata":{},"source":["## Model\n","\n","* Consists of two networks:\n","    * Online network\n","    * Target network"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-11-24T09:12:06.034302Z","iopub.status.busy":"2023-11-24T09:12:06.033356Z","iopub.status.idle":"2023-11-24T09:12:06.039365Z","shell.execute_reply":"2023-11-24T09:12:06.038400Z","shell.execute_reply.started":"2023-11-24T09:12:06.034260Z"},"trusted":true},"outputs":[],"source":["import os\n","import torch\n","import torchvision\n","from torchvision import transforms\n","import torch.nn as nn\n","import numpy as np\n","from torch.utils.data.dataloader import DataLoader\n","from torch.utils.tensorboard import SummaryWriter\n","import torch.nn.functional as F"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-11-24T09:12:06.471520Z","iopub.status.busy":"2023-11-24T09:12:06.470744Z","iopub.status.idle":"2023-11-24T09:12:06.482678Z","shell.execute_reply":"2023-11-24T09:12:06.481634Z","shell.execute_reply.started":"2023-11-24T09:12:06.471486Z"},"trusted":true},"outputs":[],"source":["class GaussianBlur(object):\n","    \"\"\"blur a single image on CPU\"\"\"\n","\n","    def __init__(self, kernel_size):\n","        radias = kernel_size // 2\n","        kernel_size = radias * 2 + 1\n","        self.blur_h = nn.Conv2d(3, 3, kernel_size=(kernel_size, 1),\n","                                stride=1, padding=0, bias=False, groups=3)\n","        self.blur_v = nn.Conv2d(3, 3, kernel_size=(1, kernel_size),\n","                                stride=1, padding=0, bias=False, groups=3)\n","        self.k = kernel_size\n","        self.r = radias\n","\n","        self.blur = nn.Sequential(\n","            nn.ReflectionPad2d(radias),\n","            self.blur_h,\n","            self.blur_v\n","        )\n","\n","        self.pil_to_tensor = transforms.ToTensor()\n","        self.tensor_to_pil = transforms.ToPILImage()\n","\n","    def __call__(self, img):\n","        img = self.pil_to_tensor(img).unsqueeze(0)\n","\n","        sigma = np.random.uniform(0.1, 2.0)\n","        x = np.arange(-self.r, self.r + 1)\n","        x = np.exp(-np.power(x, 2) / (2 * sigma * sigma))\n","        x = x / x.sum()\n","        x = torch.from_numpy(x).view(1, -1).repeat(3, 1)\n","\n","        self.blur_h.weight.data.copy_(x.view(3, 1, self.k, 1))\n","        self.blur_v.weight.data.copy_(x.view(3, 1, 1, self.k))\n","\n","        with torch.no_grad():\n","            img = self.blur(img)\n","            img = img.squeeze()\n","\n","        img = self.tensor_to_pil(img)\n","\n","        return img"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-11-24T09:12:06.902886Z","iopub.status.busy":"2023-11-24T09:12:06.902022Z","iopub.status.idle":"2023-11-24T09:12:06.908847Z","shell.execute_reply":"2023-11-24T09:12:06.907885Z","shell.execute_reply.started":"2023-11-24T09:12:06.902853Z"},"trusted":true},"outputs":[],"source":["def get_simclr_data_transforms(input_shape, s):\n","    # get a set of data augmentation transformations as described in the SimCLR paper.\n","    color_jitter = transforms.ColorJitter(0.8 * s, 0.8 * s, 0.8 * s, 0.2 * s)\n","    data_transforms = transforms.Compose([transforms.RandomResizedCrop(size=input_shape[0]),\n","                                          transforms.RandomHorizontalFlip(),\n","                                          transforms.RandomApply([color_jitter], p=0.8),\n","                                          transforms.RandomGrayscale(p=0.2),\n","                                          GaussianBlur(kernel_size=int(0.1 * input_shape[0])),\n","                                          transforms.ToTensor()])\n","    return data_transforms"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-11-24T09:12:07.302138Z","iopub.status.busy":"2023-11-24T09:12:07.301777Z","iopub.status.idle":"2023-11-24T09:12:07.307887Z","shell.execute_reply":"2023-11-24T09:12:07.307020Z","shell.execute_reply.started":"2023-11-24T09:12:07.302107Z"},"trusted":true},"outputs":[],"source":["class MultiViewDataInjector(object):\n","    def __init__(self, *args):\n","        self.transforms = args[0]\n","        self.random_flip = transforms.RandomHorizontalFlip()\n","\n","    def __call__(self, sample, *with_consistent_flipping):\n","        if with_consistent_flipping:\n","            sample = self.random_flip(sample)\n","        output = [transform(sample) for transform in self.transforms]\n","        return output"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-11-24T09:12:07.731819Z","iopub.status.busy":"2023-11-24T09:12:07.730939Z","iopub.status.idle":"2023-11-24T09:12:07.737623Z","shell.execute_reply":"2023-11-24T09:12:07.736624Z","shell.execute_reply.started":"2023-11-24T09:12:07.731786Z"},"trusted":true},"outputs":[],"source":["class MLPHead(nn.Module):\n","    def __init__(self, in_channels, mlp_hidden_size, projection_size):\n","        super(MLPHead, self).__init__()\n","\n","        self.net = nn.Sequential(\n","            nn.Linear(in_channels, mlp_hidden_size),\n","            nn.BatchNorm1d(mlp_hidden_size),\n","            nn.ReLU(inplace=True),\n","            nn.Linear(mlp_hidden_size, projection_size)\n","        )\n","\n","    def forward(self, x):\n","        return self.net(x)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-11-24T09:12:08.141765Z","iopub.status.busy":"2023-11-24T09:12:08.140877Z","iopub.status.idle":"2023-11-24T09:12:08.148932Z","shell.execute_reply":"2023-11-24T09:12:08.147714Z","shell.execute_reply.started":"2023-11-24T09:12:08.141728Z"},"trusted":true},"outputs":[],"source":["class ResNet18(torch.nn.Module):\n","    def __init__(self,model_name):\n","        super(ResNet18, self).__init__()\n","        if model_name == 'resnet18':\n","            resnet = torchvision.models.resnet18(pretrained=False)\n","        elif model_name == 'resnet50':\n","            resnet = torchvision.models.resnet50(pretrained=False)\n","\n","        self.encoder = torch.nn.Sequential(*list(resnet.children())[:-1])\n","        self.projetion = MLPHead(in_channels=resnet.fc.in_features,mlp_hidden_size = 512,projection_size = 128)\n","\n","    def forward(self, x):\n","        h = self.encoder(x)\n","        h = h.view(h.shape[0], h.shape[1])\n","        return self.projetion(h)"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2023-11-24T10:08:52.004277Z","iopub.status.busy":"2023-11-24T10:08:52.003838Z","iopub.status.idle":"2023-11-24T10:08:52.010487Z","shell.execute_reply":"2023-11-24T10:08:52.009510Z","shell.execute_reply.started":"2023-11-24T10:08:52.004236Z"},"trusted":true},"outputs":[],"source":["import os\n","from shutil import copyfile\n","\n","def _create_model_training_folder(writer, files_to_same):\n","    model_checkpoints_folder = os.path.join(writer.log_dir, 'checkpoints')\n","    if not os.path.exists(model_checkpoints_folder):\n","        os.makedirs(model_checkpoints_folder)\n","        '''for file in files_to_same:\n","            copyfile(file, os.path.join(model_checkpoints_folder, os.path.basename(file)))'''"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2023-11-24T10:08:52.453367Z","iopub.status.busy":"2023-11-24T10:08:52.452969Z","iopub.status.idle":"2023-11-24T10:08:52.473461Z","shell.execute_reply":"2023-11-24T10:08:52.472385Z","shell.execute_reply.started":"2023-11-24T10:08:52.453335Z"},"trusted":true},"outputs":[],"source":["class BYOLTrainer:\n","    def __init__(self, online_network, target_network, predictor, optimizer, device, max_epochs, m, batch_size, num_workers, checkpoint_interval,):\n","        self.online_network = online_network\n","        self.target_network = target_network\n","        self.optimizer = optimizer\n","        self.device = device\n","        self.predictor = predictor\n","        self.max_epochs = max_epochs\n","        self.writer = SummaryWriter(log_dir = '/kaggle/working/logs')\n","        self.m = m\n","        self.batch_size = batch_size\n","        self.num_workers = num_workers\n","        self.checkpoint_interval = checkpoint_interval\n","        _create_model_training_folder(self.writer, files_to_same=[\"./config/config.yaml\", \"main.py\", 'trainer.py'])\n","\n","    @torch.no_grad()\n","    def _update_target_network_parameters(self):\n","        \"\"\"\n","        Momentum update of the key encoder\n","        \"\"\"\n","        for param_q, param_k in zip(self.online_network.parameters(), self.target_network.parameters()):\n","            param_k.data = param_k.data * self.m + param_q.data * (1. - self.m)\n","\n","    @staticmethod\n","    def regression_loss(x, y):\n","        x = F.normalize(x, dim=1)\n","        y = F.normalize(y, dim=1)\n","        return 2 - 2 * (x * y).sum(dim=-1)\n","\n","    def initializes_target_network(self):\n","        # init momentum network as encoder net\n","        for param_q, param_k in zip(self.online_network.parameters(), self.target_network.parameters()):\n","            param_k.data.copy_(param_q.data)  # initialize\n","            param_k.requires_grad = False  # not update by gradient\n","\n","    def train(self, train_dataset):\n","\n","        train_loader = DataLoader(train_dataset, batch_size=self.batch_size,\n","                                  num_workers=self.num_workers, drop_last=False, shuffle=True)\n","\n","        niter = 0\n","        model_checkpoints_folder = os.path.join(self.writer.log_dir, 'checkpoints')\n","\n","        self.initializes_target_network()\n","        loss_train = []\n","\n","        for epoch_counter in range(self.max_epochs):\n","            loss_epoch = 0\n","            count = 0\n","            for (batch_view_1, batch_view_2), _ in train_loader:\n","\n","                batch_view_1 = batch_view_1.to(self.device)\n","                batch_view_2 = batch_view_2.to(self.device)\n","\n","                if niter == 0:\n","                    grid = torchvision.utils.make_grid(batch_view_1[:32])\n","                    self.writer.add_image('views_1', grid, global_step=niter)\n","\n","                    grid = torchvision.utils.make_grid(batch_view_2[:32])\n","                    self.writer.add_image('views_2', grid, global_step=niter)\n","\n","                loss = self.update(batch_view_1, batch_view_2)\n","                self.writer.add_scalar('loss', loss, global_step=niter)\n","\n","                self.optimizer.zero_grad()\n","                loss.backward()\n","                self.optimizer.step()\n","\n","                self._update_target_network_parameters()  # update the key encoder\n","                niter += 1\n","                \n","                loss_epoch += loss\n","            print(f\"Epoch: {epoch_counter}, Loss: {loss_epoch}\")\n","            loss_train.append(loss_epoch)\n","\n","            print(\"End of epoch {}\".format(epoch_counter))\n","\n","        # save checkpoints\n","        self.save_model(os.path.join(model_checkpoints_folder, 'model.pth'))\n","\n","    def update(self, batch_view_1, batch_view_2):\n","        # compute query feature\n","        predictions_from_view_1 = self.predictor(self.online_network(batch_view_1))\n","        predictions_from_view_2 = self.predictor(self.online_network(batch_view_2))\n","\n","        # compute key features\n","        with torch.no_grad():\n","            targets_to_view_2 = self.target_network(batch_view_1)\n","            targets_to_view_1 = self.target_network(batch_view_2)\n","\n","        loss = self.regression_loss(predictions_from_view_1, targets_to_view_1)\n","        loss += self.regression_loss(predictions_from_view_2, targets_to_view_2)\n","        return loss.mean()\n","\n","    def save_model(self, PATH):\n","\n","        torch.save({\n","            'online_network_state_dict': self.online_network.state_dict(),\n","            'target_network_state_dict': self.target_network.state_dict(),\n","            'optimizer_state_dict': self.optimizer.state_dict(),\n","        }, PATH)"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2023-11-24T10:08:53.329279Z","iopub.status.busy":"2023-11-24T10:08:53.328868Z","iopub.status.idle":"2023-11-24T11:24:35.340734Z","shell.execute_reply":"2023-11-24T11:24:35.339683Z","shell.execute_reply.started":"2023-11-24T10:08:53.329246Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Training with: cuda\n","Files already downloaded and verified\n","Epoch: 0, Loss: 2038.26025390625\n","End of epoch 0\n","Epoch: 1, Loss: 1229.427490234375\n","End of epoch 1\n","Epoch: 2, Loss: 1092.4007568359375\n","End of epoch 2\n","Epoch: 3, Loss: 1031.49072265625\n","End of epoch 3\n","Epoch: 4, Loss: 1002.2159423828125\n","End of epoch 4\n","Epoch: 5, Loss: 960.385986328125\n","End of epoch 5\n","Epoch: 6, Loss: 950.72314453125\n","End of epoch 6\n","Epoch: 7, Loss: 921.6815795898438\n","End of epoch 7\n","Epoch: 8, Loss: 917.8095703125\n","End of epoch 8\n","Epoch: 9, Loss: 892.4237670898438\n","End of epoch 9\n","Epoch: 10, Loss: 893.6664428710938\n","End of epoch 10\n","Epoch: 11, Loss: 881.2210083007812\n","End of epoch 11\n","Epoch: 12, Loss: 848.5782470703125\n","End of epoch 12\n","Epoch: 13, Loss: 827.1861572265625\n","End of epoch 13\n","Epoch: 14, Loss: 804.5858154296875\n","End of epoch 14\n"]}],"source":["torch.manual_seed(0)\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print(f\"Training with: {device}\")\n","\n","data_transform = get_simclr_data_transforms(s= 1, input_shape= (96,96,3))\n","\n","train_dataset = torchvision.datasets.STL10('/home/thalles/Downloads/', split='train+unlabeled', download=True,\n","                               transform=MultiViewDataInjector([data_transform, data_transform]))\n","\n","# online network\n","online_network = ResNet18('resnet18').to(device)\n","\n","# predictor network\n","predictor = MLPHead(in_channels=online_network.projetion.net[-1].out_features,\n","                    mlp_hidden_size = 512,\n","                    projection_size = 128).to(device)\n","\n","# target encoder\n","target_network = ResNet18('resnet18').to(device)\n","\n","optimizer = torch.optim.SGD(list(online_network.parameters()) + list(predictor.parameters()),\n","                            lr = 0.03,\n","                            momentum = 0.9,\n","                            weight_decay = 0.0004)\n","\n","trainer = BYOLTrainer(online_network=online_network,\n","                      target_network=target_network,\n","                      optimizer=optimizer,\n","                      predictor=predictor,\n","                      device=device,\n","                      batch_size = 64,\n","                      m = 0.996,\n","                      checkpoint_interval = 5000,\n","                      max_epochs = 15,\n","                      num_workers = 4)\n","\n","trainer.train(train_dataset)"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2023-11-24T11:37:53.114653Z","iopub.status.busy":"2023-11-24T11:37:53.113635Z","iopub.status.idle":"2023-11-24T11:37:53.121247Z","shell.execute_reply":"2023-11-24T11:37:53.120300Z","shell.execute_reply.started":"2023-11-24T11:37:53.114610Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["ResNet18(\n","  (encoder): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (4): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (5): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (6): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (7): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n","  )\n","  (projetion): MLPHead(\n","    (net): Sequential(\n","      (0): Linear(in_features=512, out_features=512, bias=True)\n","      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU(inplace=True)\n","      (3): Linear(in_features=512, out_features=128, bias=True)\n","    )\n","  )\n",")\n"]}],"source":["print(trainer.online_network)"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2023-11-24T11:38:25.281354Z","iopub.status.busy":"2023-11-24T11:38:25.280781Z","iopub.status.idle":"2023-11-24T11:38:25.287723Z","shell.execute_reply":"2023-11-24T11:38:25.286839Z","shell.execute_reply.started":"2023-11-24T11:38:25.281307Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["ResNet18(\n","  (encoder): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (4): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (5): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (6): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (7): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n","  )\n","  (projetion): MLPHead(\n","    (net): Sequential(\n","      (0): Linear(in_features=512, out_features=512, bias=True)\n","      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU(inplace=True)\n","      (3): Linear(in_features=512, out_features=128, bias=True)\n","    )\n","  )\n",")\n"]}],"source":["print(trainer.target_network)"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2023-11-24T11:38:40.868322Z","iopub.status.busy":"2023-11-24T11:38:40.867411Z","iopub.status.idle":"2023-11-24T11:38:40.873148Z","shell.execute_reply":"2023-11-24T11:38:40.872178Z","shell.execute_reply.started":"2023-11-24T11:38:40.868284Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["SGD (\n","Parameter Group 0\n","    dampening: 0\n","    differentiable: False\n","    foreach: None\n","    lr: 0.03\n","    maximize: False\n","    momentum: 0.9\n","    nesterov: False\n","    weight_decay: 0.0004\n",")\n"]}],"source":["print(trainer.optimizer)"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2023-11-24T11:36:51.539630Z","iopub.status.busy":"2023-11-24T11:36:51.538802Z","iopub.status.idle":"2023-11-24T11:36:51.793784Z","shell.execute_reply":"2023-11-24T11:36:51.792990Z","shell.execute_reply.started":"2023-11-24T11:36:51.539593Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/working/BYOL_ON_RESNET18_online_network.pth\n"]}],"source":["MODEL_PATH = '/kaggle/working/'\n","MODEL_NAME = 'BYOL_ON_RESNET18_online_network.pth'\n","MODEL_SAVE_PATH = MODEL_PATH + MODEL_NAME\n","print(MODEL_SAVE_PATH)\n","torch.save(trainer.online_network.state_dict(),MODEL_SAVE_PATH)\n","MODEL_TARGET_NETWORK = MODEL_PATH + 'BYOL_ON_RESNET18_target_network.pth'\n","torch.save(trainer.target_network.state_dict(),MODEL_TARGET_NETWORK)\n","MODEL_OPTIMIZER = MODEL_PATH + 'BYOL_ON_RESNET18_optimizer.pth'\n","torch.save(trainer.optimizer.state_dict(),MODEL_OPTIMIZER)"]},{"cell_type":"markdown","metadata":{},"source":["## LINEAR CLASSIFIER EVALUATION"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2023-11-24T11:40:35.808970Z","iopub.status.busy":"2023-11-24T11:40:35.808191Z","iopub.status.idle":"2023-11-24T11:40:49.962652Z","shell.execute_reply":"2023-11-24T11:40:49.961801Z","shell.execute_reply.started":"2023-11-24T11:40:35.808938Z"},"trusted":true},"outputs":[],"source":["data_transforms = torchvision.transforms.Compose([transforms.ToTensor()])\n","train_dataset = torchvision.datasets.STL10('/home/thalles/Downloads/', split='train', download=False,\n","                               transform=data_transforms)\n","\n","test_dataset = torchvision.datasets.STL10('/home/thalles/Downloads/', split='test', download=False,\n","                               transform=data_transforms)"]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2023-11-24T11:41:44.061105Z","iopub.status.busy":"2023-11-24T11:41:44.060367Z","iopub.status.idle":"2023-11-24T11:41:44.066207Z","shell.execute_reply":"2023-11-24T11:41:44.065237Z","shell.execute_reply.started":"2023-11-24T11:41:44.061072Z"},"trusted":true},"outputs":[],"source":["batch_size = 512\n","train_loader = DataLoader(train_dataset, batch_size=batch_size,\n","                          num_workers=0, drop_last=False, shuffle=True)\n","\n","test_loader = DataLoader(test_dataset, batch_size=batch_size,\n","                          num_workers=0, drop_last=False, shuffle=True)"]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2023-11-24T11:43:59.863432Z","iopub.status.busy":"2023-11-24T11:43:59.862605Z","iopub.status.idle":"2023-11-24T11:44:00.033096Z","shell.execute_reply":"2023-11-24T11:44:00.032188Z","shell.execute_reply.started":"2023-11-24T11:43:59.863393Z"},"trusted":true},"outputs":[],"source":["device = 'cuda' #'cuda' if torch.cuda.is_available() else 'cpu'\n","encoder = ResNet18('resnet18')\n","output_feature_dim = encoder.projetion.net[0].in_features"]},{"cell_type":"code","execution_count":52,"metadata":{"execution":{"iopub.execute_input":"2023-11-24T11:49:32.399300Z","iopub.status.busy":"2023-11-24T11:49:32.398910Z","iopub.status.idle":"2023-11-24T11:49:32.451394Z","shell.execute_reply":"2023-11-24T11:49:32.450624Z","shell.execute_reply.started":"2023-11-24T11:49:32.399268Z"},"trusted":true},"outputs":[],"source":["encoder.load_state_dict(torch.load('/kaggle/working/BYOL_ON_RESNET18_online_network.pth'))\n","encoder = torch.nn.Sequential(*list(encoder.children())[:-1])    \n","encoder = encoder.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(encoder)"]},{"cell_type":"code","execution_count":53,"metadata":{"execution":{"iopub.execute_input":"2023-11-24T11:50:10.540274Z","iopub.status.busy":"2023-11-24T11:50:10.539866Z","iopub.status.idle":"2023-11-24T11:50:10.545900Z","shell.execute_reply":"2023-11-24T11:50:10.545001Z","shell.execute_reply.started":"2023-11-24T11:50:10.540241Z"},"trusted":true},"outputs":[],"source":["class LogisticRegression(torch.nn.Module):\n","    def __init__(self, input_dim, output_dim):\n","        super(LogisticRegression, self).__init__()\n","        self.linear = torch.nn.Linear(input_dim, output_dim)\n","        \n","    def forward(self, x):\n","        return self.linear(x)"]},{"cell_type":"code","execution_count":54,"metadata":{"execution":{"iopub.execute_input":"2023-11-24T11:50:19.295856Z","iopub.status.busy":"2023-11-24T11:50:19.294719Z","iopub.status.idle":"2023-11-24T11:50:19.301286Z","shell.execute_reply":"2023-11-24T11:50:19.300452Z","shell.execute_reply.started":"2023-11-24T11:50:19.295806Z"},"trusted":true},"outputs":[],"source":["logreg = LogisticRegression(output_feature_dim, 10)\n","logreg = logreg.to(device)"]},{"cell_type":"code","execution_count":69,"metadata":{"execution":{"iopub.execute_input":"2023-11-24T11:54:32.504439Z","iopub.status.busy":"2023-11-24T11:54:32.504087Z","iopub.status.idle":"2023-11-24T11:54:32.511074Z","shell.execute_reply":"2023-11-24T11:54:32.510102Z","shell.execute_reply.started":"2023-11-24T11:54:32.504412Z"},"trusted":true},"outputs":[],"source":["def get_features_from_encoder(encoder, loader):\n","    x_train = []\n","    y_train = []\n","\n","    # get the features from the pre-trained model\n","    for i, (x, y) in enumerate(loader):\n","        with torch.no_grad():\n","            x = x.to(device)\n","            feature_vector = encoder(x)\n","            x_train.extend(feature_vector)\n","            y_train.extend(y.numpy())\n","\n","            \n","    x_train = torch.stack(x_train)\n","    y_train = torch.tensor(y_train)\n","    return x_train, y_train"]},{"cell_type":"code","execution_count":70,"metadata":{"execution":{"iopub.execute_input":"2023-11-24T11:54:32.663124Z","iopub.status.busy":"2023-11-24T11:54:32.662725Z","iopub.status.idle":"2023-11-24T11:54:38.666019Z","shell.execute_reply":"2023-11-24T11:54:38.665064Z","shell.execute_reply.started":"2023-11-24T11:54:32.663091Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Training data shape: torch.Size([5000, 512]) torch.Size([5000])\n","Testing data shape: torch.Size([8000, 512]) torch.Size([8000])\n"]}],"source":["encoder.eval()\n","x_train, y_train = get_features_from_encoder(encoder, train_loader)\n","x_test, y_test = get_features_from_encoder(encoder, test_loader)\n","\n","if len(x_train.shape) > 2:\n","    x_train = torch.mean(x_train, dim=[2, 3])\n","    x_test = torch.mean(x_test, dim=[2, 3])\n","    \n","print(\"Training data shape:\", x_train.shape, y_train.shape)\n","print(\"Testing data shape:\", x_test.shape, y_test.shape)"]},{"cell_type":"code","execution_count":71,"metadata":{"execution":{"iopub.execute_input":"2023-11-24T11:55:01.781899Z","iopub.status.busy":"2023-11-24T11:55:01.781495Z","iopub.status.idle":"2023-11-24T11:55:01.790677Z","shell.execute_reply":"2023-11-24T11:55:01.789779Z","shell.execute_reply.started":"2023-11-24T11:55:01.781864Z"},"trusted":true},"outputs":[],"source":["def create_data_loaders_from_arrays(X_train, y_train, X_test, y_test):\n","\n","    train = torch.utils.data.TensorDataset(X_train, y_train)\n","    train_loader = torch.utils.data.DataLoader(train, batch_size=64, shuffle=True)\n","\n","    test = torch.utils.data.TensorDataset(X_test, y_test)\n","    test_loader = torch.utils.data.DataLoader(test, batch_size=512, shuffle=False)\n","    return train_loader, test_loader"]},{"cell_type":"code","execution_count":89,"metadata":{"execution":{"iopub.execute_input":"2023-11-24T12:25:24.498434Z","iopub.status.busy":"2023-11-24T12:25:24.498010Z","iopub.status.idle":"2023-11-24T12:25:24.504417Z","shell.execute_reply":"2023-11-24T12:25:24.503282Z","shell.execute_reply.started":"2023-11-24T12:25:24.498401Z"},"trusted":true},"outputs":[],"source":["train_loader, test_loader = create_data_loaders_from_arrays(torch.from_numpy(x_train), y_train, x_test, y_test)"]},{"cell_type":"code","execution_count":90,"metadata":{"execution":{"iopub.execute_input":"2023-11-24T12:26:27.267359Z","iopub.status.busy":"2023-11-24T12:26:27.266416Z","iopub.status.idle":"2023-11-24T12:26:54.538855Z","shell.execute_reply":"2023-11-24T12:26:54.538086Z","shell.execute_reply.started":"2023-11-24T12:26:27.267320Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Testing accuracy: 30.9625\n","Testing accuracy: 34.2375\n","Testing accuracy: 36.3375\n","Testing accuracy: 37.775\n","Testing accuracy: 39.5375\n","Testing accuracy: 41.4875\n","Testing accuracy: 42.275\n","Testing accuracy: 42.3375\n","Testing accuracy: 41.8375\n","Testing accuracy: 41.975\n","Testing accuracy: 39.9375\n","Testing accuracy: 39.675\n","Testing accuracy: 37.0\n","Testing accuracy: 35.575\n","Testing accuracy: 34.6\n","Testing accuracy: 33.0125\n","Testing accuracy: 31.025\n","Testing accuracy: 29.9625\n","Testing accuracy: 28.45\n","Testing accuracy: 27.6375\n"]}],"source":["optimizer = torch.optim.Adam(logreg.parameters(), lr=3e-4)\n","criterion = torch.nn.CrossEntropyLoss()\n","eval_every_n_epochs = 10\n","\n","for epoch in range(200):\n","#     train_acc = []\n","    for x, y in train_loader:\n","\n","        x = x.to(device)\n","        y = y.to(device)\n","        \n","        # zero the parameter gradients\n","        optimizer.zero_grad()        \n","        \n","        logits = logreg(x)\n","        predictions = torch.argmax(logits, dim=1)\n","        \n","        loss = criterion(logits, y)\n","        \n","        loss.backward()\n","        optimizer.step()\n","    \n","    total = 0\n","    if epoch % eval_every_n_epochs == 0:\n","        correct = 0\n","        for x, y in test_loader:\n","            x = x.to(device)\n","            y = y.to(device)\n","\n","            logits = logreg(x)\n","            predictions = torch.argmax(logits, dim=1)\n","            \n","            total += y.size(0)\n","            correct += (predictions == y).sum().item()\n","            \n","        acc = 100 * correct / total\n","        print(f\"Testing accuracy: {np.mean(acc)}\")"]},{"cell_type":"markdown","metadata":{},"source":["* This is the linear classification accuracy when the encoder takes the parameters of the BYOL trained for 15 epochs."]},{"cell_type":"code","execution_count":93,"metadata":{"execution":{"iopub.execute_input":"2023-11-24T12:31:52.593655Z","iopub.status.busy":"2023-11-24T12:31:52.593264Z","iopub.status.idle":"2023-11-24T13:50:35.245122Z","shell.execute_reply":"2023-11-24T13:50:35.244065Z","shell.execute_reply.started":"2023-11-24T12:31:52.593622Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Files already downloaded and verified\n","Epoch: 0, Loss: 799.3731079101562\n","End of epoch 0\n","Epoch: 1, Loss: 802.874755859375\n","End of epoch 1\n","Epoch: 2, Loss: 797.1381225585938\n","End of epoch 2\n","Epoch: 3, Loss: 793.4573364257812\n","End of epoch 3\n","Epoch: 4, Loss: 808.0007934570312\n","End of epoch 4\n","Epoch: 5, Loss: 811.2720947265625\n","End of epoch 5\n","Epoch: 6, Loss: 810.4304809570312\n","End of epoch 6\n","Epoch: 7, Loss: 814.619384765625\n","End of epoch 7\n","Epoch: 8, Loss: 814.6397094726562\n","End of epoch 8\n","Epoch: 9, Loss: 824.9259643554688\n","End of epoch 9\n","Epoch: 10, Loss: 823.8887939453125\n","End of epoch 10\n","Epoch: 11, Loss: 831.4505004882812\n","End of epoch 11\n","Epoch: 12, Loss: 831.2811279296875\n","End of epoch 12\n","Epoch: 13, Loss: 836.8493041992188\n","End of epoch 13\n","Epoch: 14, Loss: 842.2604370117188\n","End of epoch 14\n"]}],"source":["train_dataset_second_train = torchvision.datasets.STL10('/home/thalles/Downloads/', split='train+unlabeled', download=True,\n","                               transform=MultiViewDataInjector([data_transform, data_transform]))\n","\n","trainer.train(train_dataset_second_train)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4048987,"sourceId":7037705,"sourceType":"datasetVersion"}],"dockerImageVersionId":30587,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
